{
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 8c6168e (add some own solutions to brush up my python)
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkhO60dmHc8m"
   },
   "source": [
    "# Brushing up on your Python Skills\n",
    "\n",
    "The basics of this class are taught in Python. And the neglected basics of ALP is preprocessing our texts.\n",
    "\n",
    "Preprocessing for ALP is much broader than what computer and data scientists usually mean. Philological conventions in printed and digital publications hold much more information that needs to be correctly parsed before any computational manipulation (analysis).\n",
    "\n",
<<<<<<< HEAD
    "In this notebook, we are going to provide four examples of messy texts: two in Egyptian and two in Akkadian. We are going to work through the process of how we should parse the texts, what information we are losing when parsing them, and brushing up on basic Python syntax and functions while we're at it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZMX2K-gMg5j"
   },
   "source": [
    "## Akkadian Example 1:\n",
    "\n",
    "https://cdli.mpiwg-berlin.mpg.de/artifacts/225104\n",
    "\n",
    "&P225104 = TIM 10, 134\n",
    "#atf: use lexical\n",
    "#Nippur 2N-T496; proverb; Alster proverbs\n",
    "@tablet\n",
    "@obverse\n",
    "@column 1\n",
    "1. dub-sar hu-ru\n",
    "2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne\n",
    "3. dub-sar hu-ru\n",
    "4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne\n",
    "@reverse\n",
    "@column 1\n",
    "1. igi-bi 3(disz) 3(asz) 6(disz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUwK2e7_PlFr"
   },
   "source": [
    "### Task 1:\n",
    "\n",
    "How do we turn this raw text into a list of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.320107Z",
     "start_time": "2024-05-01T09:02:48.308147Z"
    },
    "id": "Ytf3w5-dN61H",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "akk1 = \"\"\"&P225104 = TIM 10, 134\n",
    "#atf: use lexical\n",
    "#Nippur 2N-T496; proverb; Alster proverbs\n",
    "@tablet\n",
    "@obverse\n",
    "@column 1\n",
    "1. dub-sar hu-ru\n",
    "2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne\n",
    "3. dub-sar hu-ru\n",
    "4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne\n",
    "@reverse\n",
    "@column 1\n",
    "1. igi-bi 3(disz) 3(asz) 6(disz)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.327591Z",
     "start_time": "2024-05-01T09:02:48.322910Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "34ethpugN99a",
    "outputId": "a7253cbe-7867-439d-8acd-d6077257f121",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&P225104 = TIM 10, 134\\n#atf: use lexical\\n#Nippur 2N-T496; proverb; Alster proverbs\\n@tablet\\n@obverse\\n@column 1\\n1. dub-sar hu-ru\\n2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne\\n3. dub-sar hu-ru\\n4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne\\n@reverse\\n@column 1\\n1. igi-bi 3(disz) 3(asz) 6(disz)\\n'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "akk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.333142Z",
     "start_time": "2024-05-01T09:02:48.328971Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-8h5EXYPgSE",
    "outputId": "9c2b6d38-7d20-4183-bd83-e6e012eb96c2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&P225104 = TIM 10, 134',\n",
       " '#atf: use lexical',\n",
       " '#Nippur 2N-T496; proverb; Alster proverbs',\n",
       " '@tablet',\n",
       " '@obverse',\n",
       " '@column 1',\n",
       " '1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '@reverse',\n",
       " '@column 1',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)',\n",
       " '']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split string to lines of texts\n",
    "lines = akk1.split(\"\\n\")\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.338604Z",
     "start_time": "2024-05-01T09:02:48.334503Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WQbRMV_RT7L",
    "outputId": "824cdfe1-577c-4832-db58-1c2fd9ce60d2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&P225104 = TIM 10, 134',\n",
       " '#atf: use lexical',\n",
       " '#Nippur 2N-T496; proverb; Alster proverbs',\n",
       " '@tablet',\n",
       " '@obverse',\n",
       " '@column 1',\n",
       " '1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '@reverse',\n",
       " '@column 1',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove blanks\n",
    "\n",
    "lines_full = []\n",
    "for line in lines:\n",
    "  if line != \"\":\n",
    "    lines_full.append(line)\n",
    "\n",
    "lines_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.348320Z",
     "start_time": "2024-05-01T09:02:48.341651Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2kEguvRQmND",
    "outputId": "a188c992-f45c-40d8-deed-2c129a4c51e2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only lines that begin with a number\n",
    "# use regular expressions\n",
    "\n",
    "import re\n",
    "\n",
    "text_lines = []\n",
    "for line in lines_full:\n",
    "  if re.match(\"^\\d\", line) != None:\n",
    "    text_lines.append(line)\n",
    "\n",
    "text_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.354536Z",
     "start_time": "2024-05-01T09:02:48.350763Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0zRcypOTKla",
    "outputId": "d349e544-0a06-4abd-9bb1-2d84dfcfaf33",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dub-sar', 'hu-ru'], ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne'], ['dub-sar', 'hu-ru'], ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne'], ['igi-bi', '3(disz)', '3(asz)', '6(disz)']]\n",
      "-------------------------------\n",
      "['dub-sar', 'hu-ru', 'a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne', 'dub-sar', 'hu-ru', 'a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne', 'igi-bi', '3(disz)', '3(asz)', '6(disz)']\n"
     ]
    }
   ],
   "source": [
    "# separate lines into words\n",
    "\n",
    "words_appended = []\n",
    "words_extended = []\n",
    "for line in text_lines:\n",
    "  temp_words = line.split()\n",
    "  words_appended.append(temp_words[1:]) # creates list of lists\n",
    "  words_extended.extend(temp_words[1:]) # creates list\n",
    "\n",
    "print(words_appended)\n",
    "print(\"-------------------------------\")\n",
    "print(words_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.394344Z",
     "start_time": "2024-05-01T09:02:48.381948Z"
    },
    "id": "FXkWg0eVdqJN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rewrite the code above as a function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r568N_MVNFS"
   },
   "source": [
    "What information did we lose when preprocessing the texts in this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa5fciAXVT4b"
   },
   "source": [
    "### Task 2:\n",
    "\n",
    "Create a dictionary from the raw texts, of the following format:\n",
    "\n",
    "```\n",
    "{\"pnum\": ...\n",
    " \"textID\": ...\n",
    " \"surface\": [{\n",
    "  \"surfaceType\": ...\n",
    "  \"columns\": [{\n",
    "    \"columnNum\": ...\n",
    "    \"text\": [{\n",
    "      \"lineNum\": ...\n",
    "      \"words\": [..., ..., ...]\n",
    "    }]\n",
    "  }]\n",
    " }]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.400040Z",
     "start_time": "2024-05-01T09:02:48.396596Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPWuL8lWYH-U",
    "outputId": "d7cffabf-7eb3-4325-d176-5750872f0756",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&P225104 = TIM 10, 134',\n",
       " '#atf: use lexical',\n",
       " '#Nippur 2N-T496; proverb; Alster proverbs',\n",
       " '@tablet',\n",
       " '@obverse',\n",
       " '@column 1',\n",
       " '1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '@reverse',\n",
       " '@column 1',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)']"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate text into lines\n",
    "\n",
    "lines = akk1.split(\"\\n\")\n",
    "\n",
    "lines_full = []\n",
    "for line in lines:\n",
    "  if line != \"\":\n",
    "    lines_full.append(line)\n",
    "\n",
    "lines_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.404146Z",
     "start_time": "2024-05-01T09:02:48.401115Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "5iLR_THGWkxZ",
    "outputId": "b7ccf196-4dae-4451-fc69-a2694827ed1c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P225104\n",
      "TIM 10, 134\n"
     ]
    }
   ],
   "source": [
    "# store the pnum and textID in variables\n",
    "\n",
    "text_ids = lines_full[0]\n",
    "pnum, textID = text_ids.split(\"=\")\n",
    "\n",
    "pnum = pnum.strip()[1:]\n",
    "textID = textID.strip()\n",
    "print(pnum)\n",
    "print(textID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.409129Z",
     "start_time": "2024-05-01T09:02:48.405294Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYBJnaxNX8pi",
    "outputId": "7eb8e64d-7d67-4875-94a8-5f83391615e1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 10]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary for each surface (simple no regex method)\n",
    "# what do you do when you have different types of inscribed object? (e.g. cylinder, prism, bowl, slab, etc.)\n",
    "\n",
    "valid_surface_values = [\"@obverse\", \"@reverse\"]\n",
    "\n",
    "surface_idx = []\n",
    "\n",
    "for index, line in enumerate(lines_full):\n",
    "  if line in valid_surface_values: # what is dangerous in this line? if the line of text is not exactly(!) part of surface, no lines will be found\n",
    "    surface_idx.append(index)\n",
    "print(surface_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.414356Z",
     "start_time": "2024-05-01T09:02:48.410610Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaukt_6QdNuO",
    "outputId": "a406b317-41c3-46d9-f8a1-e40caae7273d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 10]\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary for each surface (complicated with regex method)\n",
    "# what do you do when you have different type of inscribed object? (e.g. cylinder, prism, bowl, slab, etc.)\n",
    "\n",
    "valid_surface_values = [\"@obverse\", \"@reverse\"]\n",
    "\n",
    "pattern = r\"^(?:\" + \"|\".join([re.escape(value) for value in valid_surface_values]) + \")\" # This is called a list comprehension\n",
    "\n",
    "surface_idx = []\n",
    "\n",
    "for index, line in enumerate(lines_full): # returns the index for the line and the content of the line\n",
    "  if re.match(pattern, line) != None:\n",
    "    surface_idx.append(index)\n",
    "print(surface_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:32:21.282331Z",
     "start_time": "2024-05-01T09:32:21.265494Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@obverse', '@reverse']\n",
      "[4, 10]\n"
     ]
    }
   ],
   "source": [
    "# same code like in cell above but without list comprehension\n",
    "# create a dictionary for each surface (complicated with regex method)\n",
    "# what do you do when you have different type of inscribed object? (e.g. cylinder, prism, bowl, slab, etc.)\n",
    "\n",
    "valid_surface_values = [\"@obverse\", \"@reverse\"]\n",
    "\n",
    "#pattern = r\"^(?:\" + \"|\".join([re.escape(value) for value in valid_surface_values]) + \")\" # This is called a list comprehension\n",
    "\n",
    "escaped_values = []\n",
    "for value in valid_surface_values:\n",
    "    escaped_values.append(re.escape(value))\n",
    "print(escaped_values)\n",
    "\n",
    "pattern = r\"^(?:\" + \"|\".join(escaped_values) + \")\"\n",
    "    \n",
    "surface_idx = []\n",
    "\n",
    "for index, line in enumerate(lines_full): # returns the index for the line and the content of the line\n",
    "  if re.match(pattern, line) != None:\n",
    "    surface_idx.append(index)\n",
    "print(surface_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.430830Z",
     "start_time": "2024-05-01T09:02:48.422183Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGKS6eNpdgfD",
    "outputId": "00ab26a1-db45-42ab-c477-93d43e8ae551",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "Surface Type: obverse\n",
      "---\n",
      "Column Number: 1\n",
      "---\n",
      "Line Number: 1\n",
      "Words: ['dub-sar', 'hu-ru']\n",
      "---\n",
      "Line Number: 2\n",
      "Words: ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne']\n",
      "---\n",
      "Line Number: 3\n",
      "Words: ['dub-sar', 'hu-ru']\n",
      "---\n",
      "Line Number: 4\n",
      "Words: ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne']\n",
      "---\n",
      "1 10\n",
      "Surface Type: reverse\n",
      "---\n",
      "Column Number: 1\n",
      "---\n",
      "Line Number: 1\n",
      "Words: ['igi-bi', '3(disz)', '3(asz)', '6(disz)']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# use surface indices to create surface dictionaries\n",
    "# surfaceType; columnNum; lineNum; words\n",
    "# surfaceType extracted using id values of lines\n",
    "# columnNum needs first to check whether a column actually exists, then extracted using regex(?)/tokenize on space for any number after the word column\n",
    "# lineNum is regex for any line that begins with a number plus any tags attached: how would be best to define line numbers, as integers or as string variables?\n",
    "# words extracted from each text line after lineNum using regex and tokenized on spaces\n",
    "\n",
    "for index, id in enumerate(surface_idx):\n",
    "    surfaceType = lines_full[id].replace('@', '')\n",
    "    print(index, id)\n",
    "    if index < len(surface_idx) - 1:\n",
    "        end_of_surface = surface_idx[index+1]\n",
    "    else:\n",
    "        end_of_surface = len(lines_full)\n",
    "\n",
    "    # Extract the text content for the current surface designation\n",
    "    surface_content = lines_full[id+1:end_of_surface]\n",
    "\n",
    "    # Print the surface type and its content\n",
    "    print(f\"Surface Type: {surfaceType}\")\n",
    "    # print(\"Content:\")\n",
    "    # print('\\n'.join(surface_content))\n",
    "    print('---')\n",
    "\n",
    "    # Extract column number, line numbers, and words for each surface content\n",
    "    for line in surface_content:\n",
    "        columnNum = None\n",
    "        lineNum = None\n",
    "        words = []\n",
    "\n",
    "        # Check if the line contains a column number\n",
    "        if '@column' in line:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    columnNum = int(parts[1])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            print(f\"Column Number: {columnNum}\")\n",
    "            print('---')\n",
    "            continue  # Skip processing the line with @column\n",
    "\n",
    "        # Check if the line contains a line number\n",
    "        if '.' in line:\n",
    "            parts = line.split('.')\n",
    "            if len(parts) >= 2:\n",
    "                lineNum = parts[0].strip()\n",
    "\n",
    "        # Tokenize the words in the line\n",
    "        if lineNum:\n",
    "            words = parts[1].strip().split()\n",
    "        else:\n",
    "            words = line.strip().split()\n",
    "\n",
    "        # Print the extracted information for each line\n",
    "        print(f\"Line Number: {lineNum}\")\n",
    "        print(f\"Words: {words}\")\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.443092Z",
     "start_time": "2024-05-01T09:02:48.436306Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nl8Qq9wbPIXy",
    "outputId": "2c2661f3-aa64-450b-c3b1-93fcd9c69f87",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pnum': 'P225104', 'textID': 'TIM 10, 134', 'surface': [{'surfaceType': 'obverse', 'columns': [{'columnNum': 1, 'text': [{'lineNum': '1', 'words': ['dub-sar', 'hu-ru']}, {'lineNum': '2', 'words': ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne']}, {'lineNum': '3', 'words': ['dub-sar', 'hu-ru']}, {'lineNum': '4', 'words': ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne']}]}]}, {'surfaceType': 'reverse', 'columns': [{'columnNum': 1, 'text': [{'lineNum': '1', 'words': ['igi-bi', '3(disz)', '3(asz)', '6(disz)']}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "# Combine the surfaces and metadata into one dictionary\n",
    "\n",
    "output = {\n",
    "    \"pnum\": pnum,\n",
    "    \"textID\": textID,\n",
    "    \"surface\": []\n",
    "}\n",
    "\n",
    "for index, id in enumerate(surface_idx):\n",
    "    surfaceType = lines_full[id].replace('@', '')\n",
    "    surface = {\n",
    "        \"surfaceType\": surfaceType,\n",
    "        \"columns\": []\n",
    "    }\n",
    "\n",
    "    if index < len(surface_idx) - 1:\n",
    "        end_of_surface = surface_idx[index+1]\n",
    "    else:\n",
    "        end_of_surface = len(lines_full)\n",
    "\n",
    "    # Extract the text content for the current surface designation\n",
    "    surface_content = lines_full[id+1:end_of_surface]\n",
    "\n",
    "    # Extract column number, line numbers, and words for each surface content\n",
    "    columnNum = None\n",
    "    column = {\n",
    "        \"columnNum\": None,\n",
    "        \"text\": []\n",
    "    }\n",
    "    for line in surface_content:\n",
    "        lineNum = None\n",
    "        words = []\n",
    "\n",
    "        # Check if the line contains a column number\n",
    "        if '@column' in line:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    columnNum = int(parts[1])\n",
    "                    column[\"columnNum\"] = columnNum\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            continue  # Skip processing the line with @column\n",
    "\n",
    "        # Check if the line contains a line number\n",
    "        if '.' in line:\n",
    "            parts = line.split('.')\n",
    "            if len(parts) >= 2:\n",
    "                lineNum = parts[0].strip()\n",
    "\n",
    "        # Tokenize the words in the line\n",
    "        if lineNum:\n",
    "            words = parts[1].strip().split()\n",
    "        else:\n",
    "            words = line.strip().split()\n",
    "\n",
    "        # Add the line information to the column\n",
    "        line_info = {\n",
    "            \"lineNum\": lineNum,\n",
    "            \"words\": words\n",
    "        }\n",
    "        column[\"text\"].append(line_info)\n",
    "\n",
    "    # Add the column to the surface\n",
    "    surface[\"columns\"].append(column)\n",
    "\n",
    "    # Add the surface to the output\n",
    "    output[\"surface\"].append(surface)\n",
    "\n",
    "# Print the output in the specified dictionary format\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.449539Z",
     "start_time": "2024-05-01T09:02:48.444656Z"
    },
    "id": "plIJDngOZr7z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the output dictionary as a JSON file\n",
    "\n",
    "import json\n",
    "with open(f\"{pnum}.json\", \"w\") as json_file:\n",
    "    json.dump(output, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.453242Z",
     "start_time": "2024-05-01T09:02:48.451033Z"
    },
    "id": "ljeV7ovmdyX9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='P225104.json' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# rewrite the code above into a function\n",
    "\n",
    "print(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAHFgXUIe4Ta"
   },
   "source": [
    "## Egyptian Example 1:\n",
    "\n",
    "A sentence from the sarcophagus of the Napatan king Aspelta (c. 600-580 BCE), found in his pyramid in Nuri, Sudan (Nu. 8), https://collections.mfa.org/objects/145117\n",
    "\n",
    "Get the context of the sentence from the Thesaurus Linguae Aegyptiae: https://thesaurus-linguae-aegyptiae.de/text/27KHHMEP4VHSDH737F2OFLKNSE/sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.481434Z",
     "start_time": "2024-05-01T09:02:48.455213Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'publication_statement': {'credit_citation': 'Doris Topmann, Sentence ID 2CBOF5UQ7JGETCXG2CQKPCWDZM <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data/blob/v17/sentences/2CBOF5UQ7JGETCXG2CQKPCWDZM.json>, in: Thesaurus Linguae Aegyptiae: Raw Data <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data>, Corpus issue 17 (31 October 2022), ed. by Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig (first published: 22 September 2023)', 'collection_editors': 'Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig', 'data_engineers': {'input_software_BTS': ['Christoph Plutte', 'Jakob Höper'], 'database_curation': ['Simon D. Schweitzer'], 'data_transformation': ['Jakob Höper', 'R. Dominik Blöse', 'Daniel A. Werning']}, 'date_published_in_TLA': '2022-10-31', 'rawdata_first_published': '2023-09-22', 'corresponding_TLA_URL': 'https://thesaurus-linguae-aegyptiae.de/sentence/2CBOF5UQ7JGETCXG2CQKPCWDZM', 'license': 'Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) <https://creativecommons.org/licenses/by-sa/4.0/>'}, 'context': {'line': 'III', 'paragraph': None, 'pos': 7, 'textId': '27KHHMEP4VHSDH737F2OFLKNSE', 'textType': 'Text', 'variants': 1}, 'eclass': 'BTSSentence', 'glyphs': {'mdc_compact': None, 'unicode': None}, 'id': '2CBOF5UQ7JGETCXG2CQKPCWDZM', 'relations': {'contains': [{'eclass': 'BTSAnnotation', 'id': 'DYJEAXFKBJAXJPVLJGWREJZJ5M', 'ranges': [{'end': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'start': '22TFIMS2CBBCFFCDSCAIT3HR3Y'}], 'type': 'ägyptologische Textsegmentierung'}], 'partOf': [{'eclass': 'BTSText', 'id': '27KHHMEP4VHSDH737F2OFLKNSE', 'name': 'Isis (HT 15, HT 14, HT 17)', 'type': 'Text'}]}, 'tokens': [{'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'PTCL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D35:N35', 'mdc_original': 'D35-N35', 'mdc_original_safe': None, 'mdc_tla': 'D35-N35', 'order': [1, 2], 'unicode': '𓂜𓈖'}, 'id': '22TFIMS2CBBCFFCDSCAIT3HR3Y', 'label': 'nn', 'lemma': {'POS': {'type': 'particle'}, 'id': '851961'}, 'transcription': {'mdc': 'nn', 'unicode': 'nn'}, 'translations': {'de': ['[Negationspartikel]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'SC.act.ngem.nom.subj_Neg.nn', 'lingGloss': 'V\\\\tam.act', 'numeric': 210020}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'W11-V28-A7', 'mdc_original': 'W11-V28-A7', 'mdc_original_safe': None, 'mdc_tla': 'W11-V28-A7', 'order': [2, 3, 4], 'unicode': '𓎼𓎛𓀉'}, 'id': 'IOLUGQXLCRGNLMTAPJ65LI7MHU', 'label': 'gḥ', 'lemma': {'POS': {'subtype': 'verb_3-lit', 'type': 'verb'}, 'id': '166480'}, 'transcription': {'mdc': 'gH', 'unicode': 'gḥ'}, 'translations': {'de': ['matt sein']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'Noun.pl.stpr.3sgm', 'lingGloss': 'N.f:pl:stpr', 'numeric': 70154}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D36:X1*F51B-Z2', 'mdc_original': 'D36-X1-F51B-Z2', 'mdc_original_safe': None, 'mdc_tla': 'D36-X1-F51B-Z2', 'order': [5, 6, 7, 8], 'unicode': '𓂝𓏏𓄹︀\\U00013440𓏥'}, 'id': 'GUVBJUGCSVF5VN55PN6RYS4YLI', 'label': 'ꜥ,t.pl', 'lemma': {'POS': {'subtype': 'substantive_fem', 'type': 'substantive'}, 'id': '34550'}, 'transcription': {'mdc': 'a.t.PL', 'unicode': 'ꜥ.t.PL'}, 'translations': {'de': ['Glied; Körperteil']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': '-3sg.m', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'I9', 'mdc_original': 'I9', 'mdc_original_safe': None, 'mdc_tla': 'I9', 'order': [9], 'unicode': '𓆑'}, 'id': 'GIHCJ27JXVAM7GDUYWGEPKBRB4', 'label': '=f', 'lemma': {'POS': {'subtype': 'personal_pronoun', 'type': 'pronoun'}, 'id': '10050'}, 'transcription': {'mdc': '=f', 'unicode': '=f'}, 'translations': {'de': ['[Suffix Pron. sg.3.m.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'dem.f.pl', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M17-Q3:N35', 'mdc_original': 'M17-Q3-N35', 'mdc_original_safe': None, 'mdc_tla': 'M17-Q3-N35', 'order': [10, 11, 12], 'unicode': '𓇋𓊪𓈖'}, 'id': 'Z6HTGGPBPRDT3OZTZNXRF2GRDA', 'label': 'jp〈t〉n', 'lemma': {'POS': {'subtype': 'demonstrative_pronoun', 'type': 'pronoun'}, 'id': '850009'}, 'transcription': {'mdc': 'jp〈t〉n', 'unicode': 'jp〈t〉n'}, 'translations': {'de': ['diese [Dem.Pron. pl.f.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'D4-Q1-A40', 'mdc_original': 'D4-Q1-A40', 'mdc_original_safe': None, 'mdc_tla': 'D4-Q1-A40', 'order': [13, 14, 15], 'unicode': '𓁹𓊨𓀭'}, 'id': 'UCFJWBLRKJG4NJWTWT22WDR2MU', 'label': 'Wsr,w', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '49461'}, 'transcription': {'mdc': 'wsr.w', 'unicode': 'Wsr.w'}, 'translations': {'de': ['Osiris (Totentitel des Verstorbenen)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M23-X1:N35', 'mdc_original': 'M23-X1-N35', 'mdc_original_safe': None, 'mdc_tla': 'M23-X1-N35', 'order': [16, 17, 18], 'unicode': '𓇓𓏏𓈖'}, 'id': 'LI5FJI4ZUJEMPIKS5RQ5HHNBUE', 'label': 'nzw', 'lemma': {'POS': {'type': 'substantive'}, 'id': '88040'}, 'transcription': {'mdc': 'nzw', 'unicode': 'nzw'}, 'translations': {'de': ['König']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:N17-N17', 'mdc_original': 'V30-N17-N17', 'mdc_original_safe': None, 'mdc_tla': 'V30-N17-N17', 'order': [19, 20, 21], 'unicode': '𓎟𓇿𓇿'}, 'id': 'ICADWHGbHkfdokpooG4eCy3Zfe8', 'label': 'nb-Tꜣ,du', 'lemma': {'POS': {'subtype': 'epith_king', 'type': 'epitheton_title'}, 'id': '400038'}, 'transcription': {'mdc': 'nb-tA.DU', 'unicode': 'nb-Tꜣ.DU'}, 'translations': {'de': ['Herr der Beiden Länder (Könige)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:D4-Aa1*X1:Y1', 'mdc_original': 'V30-D4-Aa1-X1-Y1', 'mdc_original_safe': None, 'mdc_tla': 'V30-D4-Aa1-X1-Y1', 'order': [22, 23, 24, 25, 26], 'unicode': '𓎟𓁹𓐍𓏏𓏛'}, 'id': 'ICADWHT2O1dc30SXuRZUlquIDpM', 'label': 'nb-jr(,t)-(j)ḫ,t', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '400354'}, 'transcription': {'mdc': 'nb-jr(.t)-(j)x.t', 'unicode': 'nb-jr(.t)-(j)ḫ.t'}, 'translations': {'de': ['Herr des Rituals']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': '<-M17-O34:Q3-E23-N17->', 'mdc_original': '<-M17-O34-Q3-E23-N17->', 'mdc_original_safe': None, 'mdc_tla': '<-M17-O34-Q3-E23-N17->', 'order': [18, 19, 20, 21, 22, 23], 'unicode': '𓍹\\U0001343c𓇋𓊃𓊪𓃭𓇿\\U0001343d𓍺'}, 'id': 'J3MLYALWVNAMDDG33VZ3RIEEUA', 'label': 'Jsplt', 'lemma': {'POS': {'subtype': 'kings_name', 'type': 'entity_name'}, 'id': '850103'}, 'transcription': {'mdc': 'jsplt', 'unicode': 'Jsplt'}, 'translations': {'de': ['Aspelta']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N.m:sg', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'U5:D36-P8h', 'mdc_original': 'U5-D36-P8h', 'mdc_original_safe': None, 'mdc_tla': 'U5-D36-P8h', 'order': [25, 26, 27], 'unicode': '𓌷𓂝𓊤︂'}, 'id': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'label': 'mꜣꜥ-ḫrw', 'lemma': {'POS': {'subtype': 'substantive_masc', 'type': 'substantive'}, 'id': '66750'}, 'transcription': {'mdc': 'mAa-xrw', 'unicode': 'mꜣꜥ-ḫrw'}, 'translations': {'de': ['Gerechtfertigter (der selige Tote)']}, 'type': 'word'}], 'transcription': {'mdc': 'nn gH a.t.PL=f jp〈t〉n wsr.w nzw nb-tA.DU nb-jr(.t)-(j)x.t jsplt mAa-xrw', 'unicode': 'nn gḥ ꜥ.t.PL=f jp〈t〉n Wsr.w nzw nb-Tꜣ.DU nb-jr(.t)-(j)ḫ.t Jsplt mꜣꜥ-ḫrw'}, 'translations': {'de': ['Diese seine Glieder werden nicht matt sein, (die des) Osiris Königs, des Herrn der Beiden Länder, des Herrn des Rituals, Aspelta, des Gerechtfertigten.']}, 'type': None, 'wordCount': 11, 'editors': {'author': 'Doris Topmann', 'contributors': None, 'created': '2020-12-23 12:24:26', 'type': None, 'updated': '2022-08-29 10:22:01'}}\n"
     ]
    }
   ],
   "source": [
    "# This Dictionary was created from the original json file\n",
    "\n",
    "eg1 = {'publication_statement': {'credit_citation': 'Doris Topmann, Sentence ID 2CBOF5UQ7JGETCXG2CQKPCWDZM <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data/blob/v17/sentences/2CBOF5UQ7JGETCXG2CQKPCWDZM.json>, in: Thesaurus Linguae Aegyptiae: Raw Data <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data>, Corpus issue 17 (31 October 2022), ed. by Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig (first published: 22 September 2023)', 'collection_editors': 'Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig', 'data_engineers': {'input_software_BTS': ['Christoph Plutte', 'Jakob Höper'], 'database_curation': ['Simon D. Schweitzer'], 'data_transformation': ['Jakob Höper', 'R. Dominik Blöse', 'Daniel A. Werning']}, 'date_published_in_TLA': '2022-10-31', 'rawdata_first_published': '2023-09-22', 'corresponding_TLA_URL': 'https://thesaurus-linguae-aegyptiae.de/sentence/2CBOF5UQ7JGETCXG2CQKPCWDZM', 'license': 'Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) <https://creativecommons.org/licenses/by-sa/4.0/>'}, 'context': {'line': 'III', 'paragraph': None, 'pos': 7, 'textId': '27KHHMEP4VHSDH737F2OFLKNSE', 'textType': 'Text', 'variants': 1}, 'eclass': 'BTSSentence', 'glyphs': {'mdc_compact': None, 'unicode': None}, 'id': '2CBOF5UQ7JGETCXG2CQKPCWDZM', 'relations': {'contains': [{'eclass': 'BTSAnnotation', 'id': 'DYJEAXFKBJAXJPVLJGWREJZJ5M', 'ranges': [{'end': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'start': '22TFIMS2CBBCFFCDSCAIT3HR3Y'}], 'type': 'ägyptologische Textsegmentierung'}], 'partOf': [{'eclass': 'BTSText', 'id': '27KHHMEP4VHSDH737F2OFLKNSE', 'name': 'Isis (HT 15, HT 14, HT 17)', 'type': 'Text'}]}, 'tokens': [{'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'PTCL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D35:N35', 'mdc_original': 'D35-N35', 'mdc_original_safe': None, 'mdc_tla': 'D35-N35', 'order': [1, 2], 'unicode': '𓂜𓈖'}, 'id': '22TFIMS2CBBCFFCDSCAIT3HR3Y', 'label': 'nn', 'lemma': {'POS': {'type': 'particle'}, 'id': '851961'}, 'transcription': {'mdc': 'nn', 'unicode': 'nn'}, 'translations': {'de': ['[Negationspartikel]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'SC.act.ngem.nom.subj_Neg.nn', 'lingGloss': 'V\\\\tam.act', 'numeric': 210020}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'W11-V28-A7', 'mdc_original': 'W11-V28-A7', 'mdc_original_safe': None, 'mdc_tla': 'W11-V28-A7', 'order': [2, 3, 4], 'unicode': '𓎼𓎛𓀉'}, 'id': 'IOLUGQXLCRGNLMTAPJ65LI7MHU', 'label': 'gḥ', 'lemma': {'POS': {'subtype': 'verb_3-lit', 'type': 'verb'}, 'id': '166480'}, 'transcription': {'mdc': 'gH', 'unicode': 'gḥ'}, 'translations': {'de': ['matt sein']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'Noun.pl.stpr.3sgm', 'lingGloss': 'N.f:pl:stpr', 'numeric': 70154}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D36:X1*F51B-Z2', 'mdc_original': 'D36-X1-F51B-Z2', 'mdc_original_safe': None, 'mdc_tla': 'D36-X1-F51B-Z2', 'order': [5, 6, 7, 8], 'unicode': '𓂝𓏏𓄹︀\\U00013440𓏥'}, 'id': 'GUVBJUGCSVF5VN55PN6RYS4YLI', 'label': 'ꜥ,t.pl', 'lemma': {'POS': {'subtype': 'substantive_fem', 'type': 'substantive'}, 'id': '34550'}, 'transcription': {'mdc': 'a.t.PL', 'unicode': 'ꜥ.t.PL'}, 'translations': {'de': ['Glied; Körperteil']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': '-3sg.m', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'I9', 'mdc_original': 'I9', 'mdc_original_safe': None, 'mdc_tla': 'I9', 'order': [9], 'unicode': '𓆑'}, 'id': 'GIHCJ27JXVAM7GDUYWGEPKBRB4', 'label': '=f', 'lemma': {'POS': {'subtype': 'personal_pronoun', 'type': 'pronoun'}, 'id': '10050'}, 'transcription': {'mdc': '=f', 'unicode': '=f'}, 'translations': {'de': ['[Suffix Pron. sg.3.m.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'dem.f.pl', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M17-Q3:N35', 'mdc_original': 'M17-Q3-N35', 'mdc_original_safe': None, 'mdc_tla': 'M17-Q3-N35', 'order': [10, 11, 12], 'unicode': '𓇋𓊪𓈖'}, 'id': 'Z6HTGGPBPRDT3OZTZNXRF2GRDA', 'label': 'jp〈t〉n', 'lemma': {'POS': {'subtype': 'demonstrative_pronoun', 'type': 'pronoun'}, 'id': '850009'}, 'transcription': {'mdc': 'jp〈t〉n', 'unicode': 'jp〈t〉n'}, 'translations': {'de': ['diese [Dem.Pron. pl.f.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'D4-Q1-A40', 'mdc_original': 'D4-Q1-A40', 'mdc_original_safe': None, 'mdc_tla': 'D4-Q1-A40', 'order': [13, 14, 15], 'unicode': '𓁹𓊨𓀭'}, 'id': 'UCFJWBLRKJG4NJWTWT22WDR2MU', 'label': 'Wsr,w', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '49461'}, 'transcription': {'mdc': 'wsr.w', 'unicode': 'Wsr.w'}, 'translations': {'de': ['Osiris (Totentitel des Verstorbenen)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M23-X1:N35', 'mdc_original': 'M23-X1-N35', 'mdc_original_safe': None, 'mdc_tla': 'M23-X1-N35', 'order': [16, 17, 18], 'unicode': '𓇓𓏏𓈖'}, 'id': 'LI5FJI4ZUJEMPIKS5RQ5HHNBUE', 'label': 'nzw', 'lemma': {'POS': {'type': 'substantive'}, 'id': '88040'}, 'transcription': {'mdc': 'nzw', 'unicode': 'nzw'}, 'translations': {'de': ['König']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:N17-N17', 'mdc_original': 'V30-N17-N17', 'mdc_original_safe': None, 'mdc_tla': 'V30-N17-N17', 'order': [19, 20, 21], 'unicode': '𓎟𓇿𓇿'}, 'id': 'ICADWHGbHkfdokpooG4eCy3Zfe8', 'label': 'nb-Tꜣ,du', 'lemma': {'POS': {'subtype': 'epith_king', 'type': 'epitheton_title'}, 'id': '400038'}, 'transcription': {'mdc': 'nb-tA.DU', 'unicode': 'nb-Tꜣ.DU'}, 'translations': {'de': ['Herr der Beiden Länder (Könige)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:D4-Aa1*X1:Y1', 'mdc_original': 'V30-D4-Aa1-X1-Y1', 'mdc_original_safe': None, 'mdc_tla': 'V30-D4-Aa1-X1-Y1', 'order': [22, 23, 24, 25, 26], 'unicode': '𓎟𓁹𓐍𓏏𓏛'}, 'id': 'ICADWHT2O1dc30SXuRZUlquIDpM', 'label': 'nb-jr(,t)-(j)ḫ,t', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '400354'}, 'transcription': {'mdc': 'nb-jr(.t)-(j)x.t', 'unicode': 'nb-jr(.t)-(j)ḫ.t'}, 'translations': {'de': ['Herr des Rituals']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': '<-M17-O34:Q3-E23-N17->', 'mdc_original': '<-M17-O34-Q3-E23-N17->', 'mdc_original_safe': None, 'mdc_tla': '<-M17-O34-Q3-E23-N17->', 'order': [18, 19, 20, 21, 22, 23], 'unicode': '𓍹\\U0001343c𓇋𓊃𓊪𓃭𓇿\\U0001343d𓍺'}, 'id': 'J3MLYALWVNAMDDG33VZ3RIEEUA', 'label': 'Jsplt', 'lemma': {'POS': {'subtype': 'kings_name', 'type': 'entity_name'}, 'id': '850103'}, 'transcription': {'mdc': 'jsplt', 'unicode': 'Jsplt'}, 'translations': {'de': ['Aspelta']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N.m:sg', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'U5:D36-P8h', 'mdc_original': 'U5-D36-P8h', 'mdc_original_safe': None, 'mdc_tla': 'U5-D36-P8h', 'order': [25, 26, 27], 'unicode': '𓌷𓂝𓊤︂'}, 'id': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'label': 'mꜣꜥ-ḫrw', 'lemma': {'POS': {'subtype': 'substantive_masc', 'type': 'substantive'}, 'id': '66750'}, 'transcription': {'mdc': 'mAa-xrw', 'unicode': 'mꜣꜥ-ḫrw'}, 'translations': {'de': ['Gerechtfertigter (der selige Tote)']}, 'type': 'word'}], 'transcription': {'mdc': 'nn gH a.t.PL=f jp〈t〉n wsr.w nzw nb-tA.DU nb-jr(.t)-(j)x.t jsplt mAa-xrw', 'unicode': 'nn gḥ ꜥ.t.PL=f jp〈t〉n Wsr.w nzw nb-Tꜣ.DU nb-jr(.t)-(j)ḫ.t Jsplt mꜣꜥ-ḫrw'}, 'translations': {'de': ['Diese seine Glieder werden nicht matt sein, (die des) Osiris Königs, des Herrn der Beiden Länder, des Herrn des Rituals, Aspelta, des Gerechtfertigten.']}, 'type': None, 'wordCount': 11, 'editors': {'author': 'Doris Topmann', 'contributors': None, 'created': '2020-12-23 12:24:26', 'type': None, 'updated': '2022-08-29 10:22:01'}}\n",
    "print(eg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.487302Z",
     "start_time": "2024-05-01T09:02:48.483332Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "𓂜𓈖 nn [Negationspartikel] particle 22TFIMS2CBBCFFCDSCAIT3HR3Y\n",
      "𓎼𓎛𓀉 gḥ matt sein verb IOLUGQXLCRGNLMTAPJ65LI7MHU\n",
      "𓂝𓏏𓄹︀𓑀𓏥 ꜥ.t.PL Glied; Körperteil substantive GUVBJUGCSVF5VN55PN6RYS4YLI\n",
      "𓆑 =f [Suffix Pron. sg.3.m.] pronoun GIHCJ27JXVAM7GDUYWGEPKBRB4\n",
      "𓇋𓊪𓈖 jp〈t〉n diese [Dem.Pron. pl.f.] pronoun Z6HTGGPBPRDT3OZTZNXRF2GRDA\n",
      "𓁹𓊨𓀭 Wsr.w Osiris (Totentitel des Verstorbenen) epitheton_title UCFJWBLRKJG4NJWTWT22WDR2MU\n",
      "𓇓𓏏𓈖 nzw König substantive LI5FJI4ZUJEMPIKS5RQ5HHNBUE\n",
      "𓎟𓇿𓇿 nb-Tꜣ.DU Herr der Beiden Länder (Könige) epitheton_title ICADWHGbHkfdokpooG4eCy3Zfe8\n",
      "𓎟𓁹𓐍𓏏𓏛 nb-jr(.t)-(j)ḫ.t Herr des Rituals epitheton_title ICADWHT2O1dc30SXuRZUlquIDpM\n",
      "𓍹𓐼𓇋𓊃𓊪𓃭𓇿𓐽𓍺 Jsplt Aspelta entity_name J3MLYALWVNAMDDG33VZ3RIEEUA\n",
      "𓌷𓂝𓊤︂ mꜣꜥ-ḫrw Gerechtfertigter (der selige Tote) substantive OKLGJLCEQFHU7HDRYUTYR352YA\n"
     ]
    }
   ],
   "source": [
    "# parse the dictionary (json)\n",
    "\n",
    "unicodeHiero = []\n",
    "transcription = []\n",
    "translLemma = []\n",
    "posLemma = []\n",
    "tokenID = []\n",
    "\n",
    "for text_word in eg1[\"tokens\"] :\n",
    "    print(text_word[\"glyphs\"][\"unicode\"], text_word[\"transcription\"][\"unicode\"], text_word[\"translations\"][\"de\"][0], text_word[\"lemma\"][\"POS\"][\"type\"], text_word[\"id\"] )\n",
    "    tokenID.append(text_word[\"id\"])\n",
    "    unicodeHiero.append(text_word[\"glyphs\"][\"unicode\"])\n",
    "    translLemma.append(text_word[\"translations\"][\"de\"][0])\n",
    "    posLemma.append(text_word[\"lemma\"][\"POS\"][\"type\"])\n",
    "    \n",
    "    if text_word[\"transcription\"][\"unicode\"][0] == \"=\" : # replace equal sign as it will cause trouble in spreadsheet software like MS Excel\n",
    "        transcription.append(text_word[\"transcription\"][\"unicode\"].replace(\"=\", '⸗')) # U+2E17\n",
    "    else :\n",
    "        transcription.append(text_word[\"transcription\"][\"unicode\"])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.490623Z",
     "start_time": "2024-05-01T09:02:48.488683Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the ID of this sentence\n",
    "\n",
    "sentenceID = eg1[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.969581Z",
     "start_time": "2024-05-01T09:02:48.492477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unicode_hieroglyphs</th>\n",
       "      <th>unicode_transcription</th>\n",
       "      <th>lemma_translation</th>\n",
       "      <th>part-of-speech</th>\n",
       "      <th>tokenID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>𓂜𓈖</td>\n",
       "      <td>nn</td>\n",
       "      <td>[Negationspartikel]</td>\n",
       "      <td>particle</td>\n",
       "      <td>22TFIMS2CBBCFFCDSCAIT3HR3Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>𓎼𓎛𓀉</td>\n",
       "      <td>gḥ</td>\n",
       "      <td>matt sein</td>\n",
       "      <td>verb</td>\n",
       "      <td>IOLUGQXLCRGNLMTAPJ65LI7MHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>𓂝𓏏𓄹︀𓑀𓏥</td>\n",
       "      <td>ꜥ.t.PL</td>\n",
       "      <td>Glied; Körperteil</td>\n",
       "      <td>substantive</td>\n",
       "      <td>GUVBJUGCSVF5VN55PN6RYS4YLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>𓆑</td>\n",
       "      <td>⸗f</td>\n",
       "      <td>[Suffix Pron. sg.3.m.]</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>GIHCJ27JXVAM7GDUYWGEPKBRB4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>𓇋𓊪𓈖</td>\n",
       "      <td>jp〈t〉n</td>\n",
       "      <td>diese [Dem.Pron. pl.f.]</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>Z6HTGGPBPRDT3OZTZNXRF2GRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>𓁹𓊨𓀭</td>\n",
       "      <td>Wsr.w</td>\n",
       "      <td>Osiris (Totentitel des Verstorbenen)</td>\n",
       "      <td>epitheton_title</td>\n",
       "      <td>UCFJWBLRKJG4NJWTWT22WDR2MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>𓇓𓏏𓈖</td>\n",
       "      <td>nzw</td>\n",
       "      <td>König</td>\n",
       "      <td>substantive</td>\n",
       "      <td>LI5FJI4ZUJEMPIKS5RQ5HHNBUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>𓎟𓇿𓇿</td>\n",
       "      <td>nb-Tꜣ.DU</td>\n",
       "      <td>Herr der Beiden Länder (Könige)</td>\n",
       "      <td>epitheton_title</td>\n",
       "      <td>ICADWHGbHkfdokpooG4eCy3Zfe8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>𓎟𓁹𓐍𓏏𓏛</td>\n",
       "      <td>nb-jr(.t)-(j)ḫ.t</td>\n",
       "      <td>Herr des Rituals</td>\n",
       "      <td>epitheton_title</td>\n",
       "      <td>ICADWHT2O1dc30SXuRZUlquIDpM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>𓍹𓐼𓇋𓊃𓊪𓃭𓇿𓐽𓍺</td>\n",
       "      <td>Jsplt</td>\n",
       "      <td>Aspelta</td>\n",
       "      <td>entity_name</td>\n",
       "      <td>J3MLYALWVNAMDDG33VZ3RIEEUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>𓌷𓂝𓊤︂</td>\n",
       "      <td>mꜣꜥ-ḫrw</td>\n",
       "      <td>Gerechtfertigter (der selige Tote)</td>\n",
       "      <td>substantive</td>\n",
       "      <td>OKLGJLCEQFHU7HDRYUTYR352YA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unicode_hieroglyphs unicode_transcription  \\\n",
       "0                   𓂜𓈖                    nn   \n",
       "1                  𓎼𓎛𓀉                    gḥ   \n",
       "2               𓂝𓏏𓄹︀𓑀𓏥                ꜥ.t.PL   \n",
       "3                    𓆑                    ⸗f   \n",
       "4                  𓇋𓊪𓈖                jp〈t〉n   \n",
       "5                  𓁹𓊨𓀭                 Wsr.w   \n",
       "6                  𓇓𓏏𓈖                   nzw   \n",
       "7                  𓎟𓇿𓇿              nb-Tꜣ.DU   \n",
       "8                𓎟𓁹𓐍𓏏𓏛      nb-jr(.t)-(j)ḫ.t   \n",
       "9            𓍹𓐼𓇋𓊃𓊪𓃭𓇿𓐽𓍺                 Jsplt   \n",
       "10                𓌷𓂝𓊤︂               mꜣꜥ-ḫrw   \n",
       "\n",
       "                       lemma_translation   part-of-speech  \\\n",
       "0                    [Negationspartikel]         particle   \n",
       "1                              matt sein             verb   \n",
       "2                      Glied; Körperteil      substantive   \n",
       "3                 [Suffix Pron. sg.3.m.]          pronoun   \n",
       "4                diese [Dem.Pron. pl.f.]          pronoun   \n",
       "5   Osiris (Totentitel des Verstorbenen)  epitheton_title   \n",
       "6                                  König      substantive   \n",
       "7        Herr der Beiden Länder (Könige)  epitheton_title   \n",
       "8                       Herr des Rituals  epitheton_title   \n",
       "9                                Aspelta      entity_name   \n",
       "10    Gerechtfertigter (der selige Tote)      substantive   \n",
       "\n",
       "                        tokenID  \n",
       "0    22TFIMS2CBBCFFCDSCAIT3HR3Y  \n",
       "1    IOLUGQXLCRGNLMTAPJ65LI7MHU  \n",
       "2    GUVBJUGCSVF5VN55PN6RYS4YLI  \n",
       "3    GIHCJ27JXVAM7GDUYWGEPKBRB4  \n",
       "4    Z6HTGGPBPRDT3OZTZNXRF2GRDA  \n",
       "5    UCFJWBLRKJG4NJWTWT22WDR2MU  \n",
       "6    LI5FJI4ZUJEMPIKS5RQ5HHNBUE  \n",
       "7   ICADWHGbHkfdokpooG4eCy3Zfe8  \n",
       "8   ICADWHT2O1dc30SXuRZUlquIDpM  \n",
       "9    J3MLYALWVNAMDDG33VZ3RIEEUA  \n",
       "10   OKLGJLCEQFHU7HDRYUTYR352YA  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe and fill it\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_eg = pd.DataFrame({\n",
    "    'unicode_hieroglyphs': unicodeHiero,\n",
    "    'unicode_transcription': transcription,\n",
    "    'lemma_translation': translLemma,\n",
    "    'part-of-speech': posLemma,\n",
    "    'tokenID' : tokenID\n",
    "})\n",
    "\n",
    "df_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:48.976861Z",
     "start_time": "2024-05-01T09:02:48.970774Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save as *.csv\n",
    "\n",
    "fileName = \"aspelta_TLA_Sentence_\" + sentenceID + \".csv\"\n",
    "df_eg.to_csv(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgqdyMX1Kq_8"
   },
   "source": [
    "## Akkadian Example 2:\n",
    "\n",
    "consider the following Akkadian text:\n",
    "\n",
    "http://www.achemenet.com//fr/item/?/sources-textuelles/textes-par-publication/Strassmaier_Cyrus/1665118\n",
    "\n",
    " 6 udu-nita<sub>2</sub> <i>ina</i> šu<sup>II</sup> <sup>Id</sup>en-gi a-<i>šú šá</i> <sup>Id</sup>[\n",
    "\n",
    " <i>a-na</i> 8 gín 4-<i>tú </i>kù-babbar<i> i-na</i> kù-babbar\n",
    "\n",
    " <i>šá</i> <i>i-di</i> é [ o o o ]<i> a-na</i> é-babbar-ra\n",
    "\n",
    " <i>it-ta-din</i> 5 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup><i>ka-ṣir</i>\n",
    "\n",
    " a-<i>šú šá</i> <sup>Id</sup>en-mu<i> a-na</i> 7 gín 4-<i>tú</i>\n",
    "\n",
    " kù-babbar <i>šá</i> <i>muh-hi</i> <i>dul-lu</i> <sup>I</sup>mu-mu\n",
    "\n",
    " <i>ú-šá-hi-su a-na</i> <i>lìb-bi</i> sì-<i>na</i>\n",
    "\n",
    " 1 udu-nita<sub>2</sub><i> a-na</i> 1 gín 4-<i>tú </i>kù-babbar\n",
    "\n",
    " <i>ina</i> šu<sup>II</sup> <sup>Id</sup>utu-ba-<i>šá</i><sup>!</sup> [\n",
    "\n",
    " 1 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup>DU-[\n",
    "\n",
    " <i>a-na</i> 1<sup>?</sup> gín [\n",
    "\n",
    " pap [13 udu-nita<sub>2</sub>-meš\n",
    "\n",
    " iti du<sub>6</sub> u<sub>4</sub> [o-kam] mu sag nam-lugal-la\n",
    "\n",
    " <sup>I</sup><i>ku-ra-áš</i> lugal tin-tir<sup>ki</sup> <i>u</i> kur-kur\n",
    "\n",
    "How would you preprocess this text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:26:38.626941Z",
     "start_time": "2024-05-01T09:26:38.617531Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6 udu-nita<sub>2</sub> <i>ina</i> šu<sup>II</sup> <sup>Id</sup>en-gi a-<i>šú šá</i> <sup>Id</sup>[\\n<i>a-na</i> 8 gín 4-<i>tú </i>kù-babbar<i> i-na</i> kù-babbar \\n<i>šá</i> <i>i-di</i> é [ o o o ]<i> a-na</i> é-babbar-ra \\n<i>it-ta-din</i> 5 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup><i>ka-ṣir</i> \\na-<i>šú šá</i> <sup>Id</sup>en-mu<i> a-na</i> 7 gín 4-<i>tú</i> \\nkù-babbar <i>šá</i> <i>muh-hi</i> <i>dul-lu</i> <sup>I</sup>mu-mu \\n<i>ú-šá-hi-su a-na</i> <i>lìb-bi</i> sì-<i>na</i> \\n1 udu-nita<sub>2</sub><i> a-na</i> 1 gín 4-<i>tú </i>kù-babbar \\n<i>ina</i> šu<sup>II</sup> <sup>Id</sup>utu-ba-<i>šá</i><sup>!</sup> [\\n1 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup>DU-[\\n<i>a-na</i> 1<sup>?</sup> gín [\\npap [13 udu-nita<sub>2</sub>-meš\\niti du<sub>6</sub> u<sub>4</sub> [o-kam] mu sag nam-lugal-la \\n<sup>I</sup><i>ku-ra-áš</i> lugal tin-tir<sup>ki</sup> <i>u</i> kur-kur'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## raw text\n",
    "\n",
    "akk2 = \"\"\"6 udu-nita<sub>2</sub> <i>ina</i> šu<sup>II</sup> <sup>Id</sup>en-gi a-<i>šú šá</i> <sup>Id</sup>[\n",
    "<i>a-na</i> 8 gín 4-<i>tú </i>kù-babbar<i> i-na</i> kù-babbar \n",
    "<i>šá</i> <i>i-di</i> é [ o o o ]<i> a-na</i> é-babbar-ra \n",
    "<i>it-ta-din</i> 5 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup><i>ka-ṣir</i> \n",
    "a-<i>šú šá</i> <sup>Id</sup>en-mu<i> a-na</i> 7 gín 4-<i>tú</i> \n",
    "kù-babbar <i>šá</i> <i>muh-hi</i> <i>dul-lu</i> <sup>I</sup>mu-mu \n",
    "<i>ú-šá-hi-su a-na</i> <i>lìb-bi</i> sì-<i>na</i> \n",
    "1 udu-nita<sub>2</sub><i> a-na</i> 1 gín 4-<i>tú </i>kù-babbar \n",
    "<i>ina</i> šu<sup>II</sup> <sup>Id</sup>utu-ba-<i>šá</i><sup>!</sup> [\n",
    "1 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup>DU-[\n",
    "<i>a-na</i> 1<sup>?</sup> gín [\n",
    "pap [13 udu-nita<sub>2</sub>-meš\n",
    "iti du<sub>6</sub> u<sub>4</sub> [o-kam] mu sag nam-lugal-la \n",
    "<sup>I</sup><i>ku-ra-áš</i> lugal tin-tir<sup>ki</sup> <i>u</i> kur-kur\"\"\"\n",
    "\n",
    "akk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:26:39.251124Z",
     "start_time": "2024-05-01T09:26:39.233972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 udu-nita2 <i>ina</i> šu<sup>II</sup> <sup>Id</sup>en-gi a-<i>šú šá</i> <sup>Id</sup>[\n",
      "<i>a-na</i> 8 gín 4-<i>tú</i> kù-babbar <i>i-na</i> kù-babbar \n",
      "<i>šá</i> <i>i-di</i> é [ o o o ] <i>a-na</i> é-babbar-ra \n",
      "<i>it-ta-din</i> 5 udu-nita2 <i>šá</i> <sup>I</sup><i>ka-ṣir</i> \n",
      "a-<i>šú šá</i> <sup>Id</sup>en-mu <i>a-na</i> 7 gín 4-<i>tú</i> \n",
      "kù-babbar <i>šá</i> <i>muh-hi</i> <i>dul-lu</i> <sup>I</sup>mu-mu \n",
      "<i>ú-šá-hi-su a-na</i> <i>lìb-bi</i> sì-<i>na</i> \n",
      "1 udu-nita2 <i>a-na</i> 1 gín 4-<i>tú</i> kù-babbar \n",
      "<i>ina</i> šu<sup>II</sup> <sup>Id</sup>utu-ba-<i>šá</i><sup>!</sup> [\n",
      "1 udu-nita2 <i>šá</i> <sup>I</sup>DU-[\n",
      "<i>a-na</i> 1<sup>?</sup> gín [\n",
      "pap [13 udu-nita2-meš\n",
      "iti du6 u4 [o-kam] mu sag nam-lugal-la \n",
      "<sup>I</sup><i>ku-ra-áš</i> lugal tin-tir<sup>ki</sup> <i>u</i> kur-kur\n",
      "6 udu-nita2 <i>ina</i> šu-<sup>II</sup> <sup>Id</sup>-en-gi a-<i>šú</i> <i>šá</i> <sup>Id</sup>-[\n",
      "<i>a</i>-<i>na</i> 8 gín 4-<i>tú</i> kù-babbar <i>i</i>-<i>na</i> kù-babbar \n",
      "<i>šá</i> <i>i</i>-<i>di</i> é [ o o o ] <i>a</i>-<i>na</i> é-babbar-ra \n",
      "<i>it</i>-<i>ta</i>-<i>din</i> 5 udu-nita2 <i>šá</i> <sup>I</sup>-<i>ka</i>-<i>ṣir</i> \n",
      "a-<i>šú</i> <i>šá</i> <sup>Id</sup>-en-mu <i>a</i>-<i>na</i> 7 gín 4-<i>tú</i> \n",
      "kù-babbar <i>šá</i> <i>muh</i>-<i>hi</i> <i>dul</i>-<i>lu</i> <sup>I</sup>-mu-mu \n",
      "<i>ú</i>-<i>šá</i>-<i>hi</i>-<i>su</i> <i>a</i>-<i>na</i> <i>lìb</i>-<i>bi</i> sì-<i>na</i> \n",
      "1 udu-nita2 <i>a</i>-<i>na</i> 1 gín 4-<i>tú</i> kù-babbar \n",
      "<i>ina</i> šu-<sup>II</sup> <sup>Id</sup>-utu-ba-<i>šá</i>-<sup>!</sup> [\n",
      "1 udu-nita2 <i>šá</i> <sup>I</sup>-DU-[\n",
      "<i>a</i>-<i>na</i> 1-<sup>?</sup> gín [\n",
      "pap [13 udu-nita2-meš\n",
      "iti du6 u4 [o-kam] mu sag nam-lugal-la \n",
      "-<sup>I</sup>-<i>ku</i>-<i>ra</i>-<i>áš</i> lugal tin-tir-<sup>ki</sup> <i>u</i> kur-kur\n"
     ]
    }
   ],
   "source": [
    "## Clean the raw text in akk2\n",
    "\n",
    "akk2 = akk2.replace(\"<sub>\", \"\")\n",
    "akk2 = akk2.replace(\"</sub>\", \"\")\n",
    "\n",
    "## Harmonize word and sign boundaries\n",
    "\n",
    "# Shift blank before/after <i>/</i>\n",
    "akk2 = akk2.replace(\" </i>\", \"</i> \")\n",
    "akk2 = akk2.replace(\"<i> \", \" <i>\")\n",
    "#print(akk2)\n",
    "\n",
    "import re\n",
    "# Add hyphen before <sup> tags if there is no space before the tag\n",
    "akk2 = re.sub(r'([^ ])(<sup>)', r'\\1-\\2', akk2)              \n",
    "# Add hyphen after </sup> and </i> tags if there is no space after the tag\n",
    "akk2 = re.sub(r'(</sup>|</i>)([^ ])', r'\\1-\\2', akk2)\n",
    "\n",
    "# from a-<i>šú šá</i> to a-<i>šú</i> <i>šá</i>\n",
    "pattern = r\"(<i>[^<]*)([ -])\"\n",
    "while True:\n",
    "    new_text = re.sub(pattern, r\"\\1</i>\\2<i>\", akk2)\n",
    "    if new_text == akk2:  # End loop if there are no more differences between the existing one and the one created by re substitution\n",
    "        break\n",
    "    akk2 = new_text\n",
    "\n",
    "# Replace double hyphens by simple ones\n",
    "akk2 = akk2.replace(\"--\", \"-\")\n",
    "\n",
    "print(akk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:38:21.419364Z",
     "start_time": "2024-05-01T09:38:21.399006Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'line_id': 1, 'words': [{'word_id': 1, 'signs': [{'sign': '6', 'sign_function': 'logogram'}]}, {'word_id': 2, 'signs': [{'sign': 'udu', 'sign_function': 'logogram'}, {'sign': 'nita2', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'ina', 'sign_function': 'phonogram'}]}, {'word_id': 4, 'signs': [{'sign': 'šu', 'sign_function': 'logogram'}, {'sign': 'II', 'sign_function': 'classifier'}]}, {'word_id': 5, 'signs': [{'sign': 'Id', 'sign_function': 'classifier'}, {'sign': 'en', 'sign_function': 'logogram'}, {'sign': 'gi', 'sign_function': 'logogram'}]}, {'word_id': 6, 'signs': [{'sign': 'a', 'sign_function': 'logogram'}, {'sign': 'šú', 'sign_function': 'phonogram'}]}, {'word_id': 7, 'signs': [{'sign': 'šá', 'sign_function': 'phonogram'}]}, {'word_id': 8, 'signs': [{'sign': 'Id', 'sign_function': 'classifier'}, {'sign': '[', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 2, 'words': [{'word_id': 1, 'signs': [{'sign': 'a', 'sign_function': 'phonogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': '8', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'gín', 'sign_function': 'logogram'}]}, {'word_id': 4, 'signs': [{'sign': '4', 'sign_function': 'logogram'}, {'sign': 'tú', 'sign_function': 'phonogram'}]}, {'word_id': 5, 'signs': [{'sign': 'kù', 'sign_function': 'logogram'}, {'sign': 'babbar', 'sign_function': 'logogram'}]}, {'word_id': 6, 'signs': [{'sign': 'i', 'sign_function': 'phonogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}, {'word_id': 7, 'signs': [{'sign': 'kù', 'sign_function': 'logogram'}, {'sign': 'babbar', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 3, 'words': [{'word_id': 1, 'signs': [{'sign': 'šá', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': 'i', 'sign_function': 'phonogram'}, {'sign': 'di', 'sign_function': 'phonogram'}]}, {'word_id': 3, 'signs': [{'sign': 'é', 'sign_function': 'logogram'}]}, {'word_id': 4, 'signs': [{'sign': '[', 'sign_function': 'logogram'}]}, {'word_id': 5, 'signs': [{'sign': 'o', 'sign_function': 'logogram'}]}, {'word_id': 6, 'signs': [{'sign': 'o', 'sign_function': 'logogram'}]}, {'word_id': 7, 'signs': [{'sign': 'o', 'sign_function': 'logogram'}]}, {'word_id': 8, 'signs': [{'sign': ']', 'sign_function': 'logogram'}]}, {'word_id': 9, 'signs': [{'sign': 'a', 'sign_function': 'phonogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}, {'word_id': 10, 'signs': [{'sign': 'é', 'sign_function': 'logogram'}, {'sign': 'babbar', 'sign_function': 'logogram'}, {'sign': 'ra', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 4, 'words': [{'word_id': 1, 'signs': [{'sign': 'it', 'sign_function': 'phonogram'}, {'sign': 'ta', 'sign_function': 'phonogram'}, {'sign': 'din', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': '5', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'udu', 'sign_function': 'logogram'}, {'sign': 'nita2', 'sign_function': 'logogram'}]}, {'word_id': 4, 'signs': [{'sign': 'šá', 'sign_function': 'phonogram'}]}, {'word_id': 5, 'signs': [{'sign': 'I', 'sign_function': 'classifier'}, {'sign': 'ka', 'sign_function': 'phonogram'}, {'sign': 'ṣir', 'sign_function': 'phonogram'}]}]}\n",
      "{'line_id': 5, 'words': [{'word_id': 1, 'signs': [{'sign': 'a', 'sign_function': 'logogram'}, {'sign': 'šú', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': 'šá', 'sign_function': 'phonogram'}]}, {'word_id': 3, 'signs': [{'sign': 'Id', 'sign_function': 'classifier'}, {'sign': 'en', 'sign_function': 'logogram'}, {'sign': 'mu', 'sign_function': 'logogram'}]}, {'word_id': 4, 'signs': [{'sign': 'a', 'sign_function': 'phonogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}, {'word_id': 5, 'signs': [{'sign': '7', 'sign_function': 'logogram'}]}, {'word_id': 6, 'signs': [{'sign': 'gín', 'sign_function': 'logogram'}]}, {'word_id': 7, 'signs': [{'sign': '4', 'sign_function': 'logogram'}, {'sign': 'tú', 'sign_function': 'phonogram'}]}]}\n",
      "{'line_id': 6, 'words': [{'word_id': 1, 'signs': [{'sign': 'kù', 'sign_function': 'logogram'}, {'sign': 'babbar', 'sign_function': 'logogram'}]}, {'word_id': 2, 'signs': [{'sign': 'šá', 'sign_function': 'phonogram'}]}, {'word_id': 3, 'signs': [{'sign': 'muh', 'sign_function': 'phonogram'}, {'sign': 'hi', 'sign_function': 'phonogram'}]}, {'word_id': 4, 'signs': [{'sign': 'dul', 'sign_function': 'phonogram'}, {'sign': 'lu', 'sign_function': 'phonogram'}]}, {'word_id': 5, 'signs': [{'sign': 'I', 'sign_function': 'classifier'}, {'sign': 'mu', 'sign_function': 'logogram'}, {'sign': 'mu', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 7, 'words': [{'word_id': 1, 'signs': [{'sign': 'ú', 'sign_function': 'phonogram'}, {'sign': 'šá', 'sign_function': 'phonogram'}, {'sign': 'hi', 'sign_function': 'phonogram'}, {'sign': 'su', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': 'a', 'sign_function': 'phonogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}, {'word_id': 3, 'signs': [{'sign': 'lìb', 'sign_function': 'phonogram'}, {'sign': 'bi', 'sign_function': 'phonogram'}]}, {'word_id': 4, 'signs': [{'sign': 'sì', 'sign_function': 'logogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}]}\n",
      "{'line_id': 8, 'words': [{'word_id': 1, 'signs': [{'sign': '1', 'sign_function': 'logogram'}]}, {'word_id': 2, 'signs': [{'sign': 'udu', 'sign_function': 'logogram'}, {'sign': 'nita2', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'a', 'sign_function': 'phonogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}, {'word_id': 4, 'signs': [{'sign': '1', 'sign_function': 'logogram'}]}, {'word_id': 5, 'signs': [{'sign': 'gín', 'sign_function': 'logogram'}]}, {'word_id': 6, 'signs': [{'sign': '4', 'sign_function': 'logogram'}, {'sign': 'tú', 'sign_function': 'phonogram'}]}, {'word_id': 7, 'signs': [{'sign': 'kù', 'sign_function': 'logogram'}, {'sign': 'babbar', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 9, 'words': [{'word_id': 1, 'signs': [{'sign': 'ina', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': 'šu', 'sign_function': 'logogram'}, {'sign': 'II', 'sign_function': 'classifier'}]}, {'word_id': 3, 'signs': [{'sign': 'Id', 'sign_function': 'classifier'}, {'sign': 'utu', 'sign_function': 'logogram'}, {'sign': 'ba', 'sign_function': 'logogram'}, {'sign': 'šá', 'sign_function': 'phonogram'}, {'sign': '!', 'sign_function': 'classifier'}]}, {'word_id': 4, 'signs': [{'sign': '[', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 10, 'words': [{'word_id': 1, 'signs': [{'sign': '1', 'sign_function': 'logogram'}]}, {'word_id': 2, 'signs': [{'sign': 'udu', 'sign_function': 'logogram'}, {'sign': 'nita2', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'šá', 'sign_function': 'phonogram'}]}, {'word_id': 4, 'signs': [{'sign': 'I', 'sign_function': 'classifier'}, {'sign': 'DU', 'sign_function': 'logogram'}, {'sign': '[', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 11, 'words': [{'word_id': 1, 'signs': [{'sign': 'a', 'sign_function': 'phonogram'}, {'sign': 'na', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': '1', 'sign_function': 'logogram'}, {'sign': '?', 'sign_function': 'classifier'}]}, {'word_id': 3, 'signs': [{'sign': 'gín', 'sign_function': 'logogram'}]}, {'word_id': 4, 'signs': [{'sign': '[', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 12, 'words': [{'word_id': 1, 'signs': [{'sign': 'pap', 'sign_function': 'logogram'}]}, {'word_id': 2, 'signs': [{'sign': '[13', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'udu', 'sign_function': 'logogram'}, {'sign': 'nita2', 'sign_function': 'logogram'}, {'sign': 'meš', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 13, 'words': [{'word_id': 1, 'signs': [{'sign': 'iti', 'sign_function': 'logogram'}]}, {'word_id': 2, 'signs': [{'sign': 'du6', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'u4', 'sign_function': 'logogram'}]}, {'word_id': 4, 'signs': [{'sign': '[o', 'sign_function': 'logogram'}, {'sign': 'kam]', 'sign_function': 'logogram'}]}, {'word_id': 5, 'signs': [{'sign': 'mu', 'sign_function': 'logogram'}]}, {'word_id': 6, 'signs': [{'sign': 'sag', 'sign_function': 'logogram'}]}, {'word_id': 7, 'signs': [{'sign': 'nam', 'sign_function': 'logogram'}, {'sign': 'lugal', 'sign_function': 'logogram'}, {'sign': 'la', 'sign_function': 'logogram'}]}]}\n",
      "{'line_id': 14, 'words': [{'word_id': 1, 'signs': [{'sign': '', 'sign_function': 'logogram'}, {'sign': 'I', 'sign_function': 'classifier'}, {'sign': 'ku', 'sign_function': 'phonogram'}, {'sign': 'ra', 'sign_function': 'phonogram'}, {'sign': 'áš', 'sign_function': 'phonogram'}]}, {'word_id': 2, 'signs': [{'sign': 'lugal', 'sign_function': 'logogram'}]}, {'word_id': 3, 'signs': [{'sign': 'tin', 'sign_function': 'logogram'}, {'sign': 'tir', 'sign_function': 'logogram'}, {'sign': 'ki', 'sign_function': 'classifier'}]}, {'word_id': 4, 'signs': [{'sign': 'u', 'sign_function': 'phonogram'}]}, {'word_id': 5, 'signs': [{'sign': 'kur', 'sign_function': 'logogram'}, {'sign': 'kur', 'sign_function': 'logogram'}]}]}\n"
     ]
    }
   ],
   "source": [
    "## Create a dictionary with annotations\n",
    "\n",
    "akk2_lineList = akk2.split(\"\\n\")\n",
    "\n",
    "lines_list = []\n",
    "line_count = 1\n",
    "for line in akk2_lineList:\n",
    "    temp_words = line.split()\n",
    "    line_dict = {}\n",
    "    \n",
    "    line_dict['line_id'] = line_count\n",
    "    line_dict['words'] = temp_words\n",
    "\n",
    "    lines_list.append(line_dict)\n",
    "    line_count += 1\n",
    "\n",
    "#print(lines_list)\n",
    "\n",
    "for line in lines_list :\n",
    "    subword_list = []\n",
    "    word_count = 1\n",
    "    \n",
    "    for word in line['words'] :\n",
    "        subword_dict = {}\n",
    "        \n",
    "        sign_list = []\n",
    "        \n",
    "        if '-' in word: # if more than one sign, separated by hyphen\n",
    "            temp_signs = word.split('-')\n",
    "            sign_list.extend(temp_signs)\n",
    "        else : # if only individual sign \n",
    "            sign_list.append(word)\n",
    "        \n",
    "        signs_per_word = []\n",
    "        for sign in sign_list :\n",
    "            signs_per_word.append(sign)\n",
    "        \n",
    "        subword_dict['word_id'] = word_count\n",
    "        word_count += 1  \n",
    "        subword_dict['signs'] = signs_per_word\n",
    "        \n",
    "        list_sign_func_dict = []\n",
    "        for sign in subword_dict['signs'] :\n",
    "            sign_func_dict = {}\n",
    "            #print(sign)\n",
    "            if sign.startswith('<i>') and sign.endswith('</i>') :\n",
    "                sign_func_dict['sign'] = sign[3:-4]\n",
    "                sign_func_dict['sign_function'] = 'phonogram'\n",
    "               # sign = \n",
    "            elif sign.startswith('<sup>') and sign.endswith('</sup>') :\n",
    "                sign_func_dict['sign'] = sign[5:-6]\n",
    "                sign_func_dict['sign_function'] = 'classifier'\n",
    "            else:\n",
    "                sign_func_dict['sign'] = sign\n",
    "                sign_func_dict['sign_function'] = 'logogram'\n",
    "                \n",
    "            list_sign_func_dict.append(sign_func_dict)\n",
    "        #print(list_sign_func_dict)\n",
    "        \n",
    "            \n",
    "        subword_dict['signs'] = list_sign_func_dict\n",
    "        subword_list.append(subword_dict)\n",
    "\n",
    "    line['words'] = subword_list\n",
    "    \n",
    "\n",
    "#print(lines_list)    \n",
    "for line in lines_list:\n",
    "    print(line)\n",
    "    #for words in line:\n",
    "    #    print(line['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDXxfebde9kR"
   },
   "source": [
    "## Egyptian Example 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:49.013299Z",
     "start_time": "2024-05-01T09:02:49.013291Z"
    },
    "id": "e6CfHB0KNVaf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eg2_csv = \"\"\",text,line,word,ref,frag,norm,unicode_word,unicode,lemma_id,cf,pos,sense\n",
    "92,3Z5EM77HJFCOPKZDDZFEMI6KVY,5,7,3Z5EM77HJFCOPKZDDZFEMI6KVY.5.7,gꜣu̯.w,gꜣu̯.w,<g>V96</g>𓅱,\"['<', 'g', '>', 'V', '9', '6', '<', '/', 'g', '>', '𓅱']\",166210,gꜣu̯,VERB,eng sein; entbehren; (jmdn.) Not leiden lassen\n",
    "151,4WVXFJZFLNAYHP3Y5O5SLWD7DA,2,2,4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.2,nꜥw,nꜥw,𓈖𓂝𓅱<g>I14C</g>𓏤,\"['𓈖', '𓂝', '𓅱', '<', 'g', '>', 'I', '1', '4', 'C', '<', '/', 'g', '>', '𓏤']\",80510,Nꜥw,PROPN,Sich windender (Personifikation der Schlange)\n",
    "153,4WVXFJZFLNAYHP3Y5O5SLWD7DA,2,5,4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.5,nꜥw,nꜥw,𓈖𓂝𓅱<g>I14C</g>𓏤,\"['𓈖', '𓂝', '𓅱', '<', 'g', '>', 'I', '1', '4', 'C', '<', '/', 'g', '>', '𓏤']\",80510,Nꜥw,PROPN,Sich windender (Personifikation der Schlange)\n",
    "200,67HZI45S3REA3LWVZOKJ6QJOIE,14,9,67HZI45S3REA3LWVZOKJ6QJOIE.14.9,nbi̯.n,nbi̯.n,𓈖𓎟𓃀<g>D107</g>𓈖,\"['𓈖', '𓎟', '𓃀', '<', 'g', '>', 'D', '1', '0', '7', '<', '/', 'g', '>', '𓈖']\",82520,nbi̯,VERB,schmelzen; gießen\n",
    "204,67HZI45S3REA3LWVZOKJ6QJOIE,14,13,67HZI45S3REA3LWVZOKJ6QJOIE.14.13,nḏr.n,nḏr.n,𓈖𓇦𓂋<g>U19A</g>𓆱𓈖,\"['𓈖', '𓇦', '𓂋', '<', 'g', '>', 'U', '1', '9', 'A', '<', '/', 'g', '>', '𓆱', '𓈖']\",91630,nḏr,VERB,(Holz) bearbeiten; zimmern\n",
    "206,67HZI45S3REA3LWVZOKJ6QJOIE,14,15,67HZI45S3REA3LWVZOKJ6QJOIE.14.15,b(w)n.wDU,bwn.wDU,𓃀𓈖𓏌𓅱<g>T86</g><g>T86</g>,\"['𓃀', '𓈖', '𓏌', '𓅱', '<', 'g', '>', 'T', '8', '6', '<', '/', 'g', '>', '<', 'g', '>', 'T', '8', '6', '<', '/', 'g', '>']\",55330,bwn,NOUN,Speerspitzen (des Fischspeeres)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:49.014542Z",
     "start_time": "2024-05-01T09:02:49.014528Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Convert the string into a StringIO object\n",
    "# This is only necessary because we presented the csv as a string not as a file that is loaded into the notebook\n",
    "csv_data = StringIO(eg2_csv)\n",
    "\n",
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_csv(csv_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T09:02:49.015676Z",
     "start_time": "2024-05-01T09:02:49.015667Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_tags(text):\n",
    "    parts = []  # List to collect output of the function\n",
    "    while '<g>' in text and '</g>' in text:\n",
    "        pre, rest = text.split('<g>', 1)  # splits at the first <g> found\n",
    "        tag_content, post = rest.split('</g>', 1)  # splits the rest at the first </g> found\n",
    "\n",
    "        # adds elements before the first <g></g> tag to the List\n",
    "        parts.extend(pre)\n",
    "\n",
    "        #  adds element inside the first <g></g> tag to the List\n",
    "        parts.append(tag_content)\n",
    "\n",
    "        # text variable is set to remaining text\n",
    "        text = post\n",
    "\n",
    "    # After last tag found, the remainder of the text is split and added to the List\n",
    "    parts.extend(text)\n",
    "    return parts\n",
    "\n",
    "def process_text(text):\n",
    "    if pd.isna(text): # deals with NaN\n",
    "        return []\n",
    "    else:\n",
    "        return split_tags(text)\n",
    "\n",
    "# apply functions to every row of the column 'unicode_word'\n",
    "df['unicode_splitted'] = df['unicode_word'].apply(process_text)\n",
    "# delete obsolete column\n",
    "df.drop('unicode', axis=1, inplace=True)\n",
    "\n",
    "df\n",
    "#df.to_csv(\"EG-TLA-example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
=======
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
=======
    "In this notebook, we are going to provide four examples of messy texts: one in Egyptian and two in Akkadian. We are going to work through the process of how we should parse the texts, what information we are losing when parsing them, and brushing up on basic Python syntax and functions while we're at it."
   ]
>>>>>>> 8c6168e (add some own solutions to brush up my python)
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZMX2K-gMg5j"
   },
   "source": [
    "## Akkadian Example 1:\n",
    "\n",
    "https://cdli.mpiwg-berlin.mpg.de/artifacts/225104\n",
    "\n",
    "&P225104 = TIM 10, 134\n",
    "#atf: use lexical\n",
    "#Nippur 2N-T496; proverb; Alster proverbs\n",
    "@tablet\n",
    "@obverse\n",
    "@column 1\n",
    "1. dub-sar hu-ru\n",
    "2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne\n",
    "3. dub-sar hu-ru\n",
    "4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne\n",
    "@reverse\n",
    "@column 1\n",
    "1. igi-bi 3(disz) 3(asz) 6(disz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUwK2e7_PlFr"
   },
   "source": [
    "### Task 1:\n",
    "\n",
    "How do we turn this raw text into a list of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ytf3w5-dN61H"
   },
   "outputs": [],
   "source": [
    "akk1 = \"\"\"&P225104 = TIM 10, 134\n",
    "#atf: use lexical\n",
    "#Nippur 2N-T496; proverb; Alster proverbs\n",
    "@tablet\n",
    "@obverse\n",
    "@column 1\n",
    "1. dub-sar hu-ru\n",
    "2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne\n",
    "3. dub-sar hu-ru\n",
    "4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne\n",
    "@reverse\n",
    "@column 1\n",
    "1. igi-bi 3(disz) 3(asz) 6(disz)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "34ethpugN99a",
    "outputId": "65b977de-6337-4536-ab27-e06c2ac859d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&P225104',\n",
       " '=',\n",
       " 'TIM',\n",
       " '10,',\n",
       " '134',\n",
       " '#atf:',\n",
       " 'use',\n",
       " 'lexical',\n",
       " '#Nippur',\n",
       " '2N-T496;',\n",
       " 'proverb;',\n",
       " 'Alster',\n",
       " 'proverbs',\n",
       " '@tablet',\n",
       " '@obverse',\n",
       " '@column',\n",
       " '1',\n",
       " '1.',\n",
       " 'dub-sar',\n",
       " 'hu-ru',\n",
       " '2.',\n",
       " 'a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3.',\n",
       " 'dub-sar',\n",
       " 'hu-ru',\n",
       " '4.',\n",
       " 'a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '@reverse',\n",
       " '@column',\n",
       " '1',\n",
       " '1.',\n",
       " 'igi-bi',\n",
       " '3(disz)',\n",
       " '3(asz)',\n",
       " '6(disz)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
<<<<<<< HEAD
  ]
}
>>>>>>> 724b2a0 (Create 01_Python_Brush_up.ipynb)
=======
   ],
   "source": [
    "akk1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-8h5EXYPgSE",
    "outputId": "ce9e55d7-9f50-4fd5-e7d9-50c8d4a99699"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&P225104 = TIM 10, 134',\n",
       " '#atf: use lexical',\n",
       " '#Nippur 2N-T496; proverb; Alster proverbs',\n",
       " '@tablet',\n",
       " '@obverse',\n",
       " '@column 1',\n",
       " '1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '@reverse',\n",
       " '@column 1',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split string to lines of texts\n",
    "lines = akk1.split(\"\\n\")\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WQbRMV_RT7L",
    "outputId": "678297d2-b214-4287-b188-040413c0e38b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&P225104 = TIM 10, 134',\n",
       " '#atf: use lexical',\n",
       " '#Nippur 2N-T496; proverb; Alster proverbs',\n",
       " '@tablet',\n",
       " '@obverse',\n",
       " '@column 1',\n",
       " '1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '@reverse',\n",
       " '@column 1',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove blanks\n",
    "lines_full = [line for line in akk1.split(\"\\n\") if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2kEguvRQmND",
    "outputId": "035d0b3d-39d2-473b-a253-dbf954f81101"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only lines that begin with a number\n",
    "# use regular expressions\n",
    "\n",
    "import re\n",
    "text_lines = [line for line in lines_full if re.match(r\"^\\d\", line)]\n",
    "text_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0zRcypOTKla",
    "outputId": "282957fe-d9d0-410a-8e41-3fa02d32fd24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dub-sar', 'hu-ru'], ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne'], ['dub-sar', 'hu-ru'], ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne'], ['igi-bi', '3(disz)', '3(asz)', '6(disz)']]\n",
      "-------------------------------\n",
      "['dub-sar', 'hu-ru', 'a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne', 'dub-sar', 'hu-ru', 'a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne', 'igi-bi', '3(disz)', '3(asz)', '6(disz)']\n"
     ]
    }
   ],
   "source": [
    "# separate lines into words\n",
    "\n",
    "words_appended = []\n",
    "words_extended = []\n",
    "for line in text_lines:\n",
    "  temp_words = line.split()\n",
    "  words_appended.append(temp_words[1:]) # creates list of lists\n",
    "  words_extended.extend(temp_words[1:]) # creates list\n",
    "\n",
    "print(words_appended)\n",
    "print(\"-------------------------------\")\n",
    "print(words_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "FXkWg0eVdqJN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['dub-sar', 'hu-ru'],\n",
       " ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne'],\n",
       " ['dub-sar', 'hu-ru'],\n",
       " ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne'],\n",
       " ['igi-bi', '3(disz)', '3(asz)', '6(disz)']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rewrite the code above as a function\n",
    "\n",
    "from typing import List\n",
    "\n",
    "def words_of_lines(text: str) -> List[List[str]]:\n",
    "    return [\n",
    "        line.split()[1:]\n",
    "        for line in text.split(\"\\n\") \n",
    "        if re.match(r\"^\\d\", line)\n",
    "    ]\n",
    "\n",
    "words_of_lines(akk1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r568N_MVNFS"
   },
   "source": [
    "What information did we lose when preprocessing the texts in this way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa5fciAXVT4b"
   },
   "source": [
    "### Task 2:\n",
    "\n",
    "Create a dictionary from the raw texts, of the following format:\n",
    "\n",
    "```\n",
    "{\"pnum\": ...\n",
    " \"textID\": ...\n",
    " \"surface\": [{\n",
    "  \"surfaceType\": ...\n",
    "  \"columns\": [{\n",
    "    \"columnNum\": ...\n",
    "    \"text\": [{\n",
    "      \"lineNum\": ...\n",
    "      \"words\": [..., ..., ...]\n",
    "    }]\n",
    "  }]\n",
    " }]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPWuL8lWYH-U",
    "outputId": "162648f8-4eed-464e-cbf6-2c8b4051cd17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['&P225104 = TIM 10, 134',\n",
       " '#atf: use lexical',\n",
       " '#Nippur 2N-T496; proverb; Alster proverbs',\n",
       " '@tablet',\n",
       " '@obverse',\n",
       " '@column 1',\n",
       " '1. dub-sar hu-ru',\n",
       " '2. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne',\n",
       " '3. dub-sar hu-ru',\n",
       " '4. a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne',\n",
       " '@reverse',\n",
       " '@column 1',\n",
       " '1. igi-bi 3(disz) 3(asz) 6(disz)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate text into lines\n",
    "\n",
    "lines = akk1.split(\"\\n\")\n",
    "\n",
    "lines_full = []\n",
    "for line in lines:\n",
    "  if line != \"\":\n",
    "    lines_full.append(line)\n",
    "\n",
    "lines_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iLR_THGWkxZ",
    "outputId": "2c1c6874-3a39-4a93-d105-877f3ebabd7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P225104\n",
      "TIM 10, 134\n"
     ]
    }
   ],
   "source": [
    "# store the pnum and textID in variables\n",
    "\n",
    "text_ids = lines_full[0]\n",
    "pnum, textID = text_ids.split(\"=\")\n",
    "\n",
    "pnum = pnum.strip()[1:]\n",
    "textID = textID.strip()\n",
    "print(pnum)\n",
    "print(textID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYBJnaxNX8pi",
    "outputId": "0c58c64f-60e5-4f54-e914-aabb6315825b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 10]\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "# create a dictionary for each surface (simple no regex method)\n",
    "# what do you do when you have different type of inscribed object? (e.g. cylinder, prism, bowl, slab, etc.)\n",
    "\n",
    "valid_surface_values = [\"@obverse\", \"@reverse\"]\n",
    "\n",
    "surface_idx = []\n",
    "\n",
    "for index, line in enumerate(lines_full):\n",
    "  if line in valid_surface_values: # what is dangerous in this line? if the line of text is not exactly(!) part of surface, no lines will be found\n",
    "    surface_idx.append(index)\n",
    "print(surface_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaukt_6QdNuO",
    "outputId": "de7f0346-54ed-4a10-a446-9ec54493aae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 10]\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "# create a dictionary for each surface (complicated with regex method)\n",
    "# what do you do when you have different type of inscribed object? (e.g. cylinder, prism, bowl, slab, etc.)\n",
    "\n",
    "valid_surface_values = [\"@obverse\", \"@reverse\"]\n",
    "\n",
    "pattern = r\"^(?:\" + \"|\".join([re.escape(value) for value in valid_surface_values]) + \")\"\n",
    "\n",
    "surface_idx = []\n",
    "\n",
    "for index, line in enumerate(lines_full):\n",
    "  if re.match(pattern, line) != None:\n",
    "    surface_idx.append(index)\n",
    "print(surface_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGKS6eNpdgfD",
    "outputId": "913e6469-4e1d-4faf-a908-25c7b30f8201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4\n",
      "Surface Type: obverse\n",
      "---\n",
      "Column Number: 1\n",
      "---\n",
      "Line Number: 1\n",
      "Words: ['dub-sar', 'hu-ru']\n",
      "---\n",
      "Line Number: 2\n",
      "Words: ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne']\n",
      "---\n",
      "Line Number: 3\n",
      "Words: ['dub-sar', 'hu-ru']\n",
      "---\n",
      "Line Number: 4\n",
      "Words: ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne']\n",
      "---\n",
      "1 10\n",
      "Surface Type: reverse\n",
      "---\n",
      "Column Number: 1\n",
      "---\n",
      "Line Number: 1\n",
      "Words: ['igi-bi', '3(disz)', '3(asz)', '6(disz)']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "# use surface indices to create surface dictionaries\n",
    "# surfaceType; columnNum; lineNum; words\n",
    "# surfaceType extracted using id values of lines\n",
    "# columnNum needs first to check whether a column actually exists, then extracted using regex(?)/tokenize on space for any number after the word column\n",
    "# lineNum is regex for any line that begins with a number plus any tags attached: how would be best to define line numbers, as integers or as string variables?\n",
    "# words extracted from each text line after lineNum using regex and tokenized on spaces\n",
    "\n",
    "for index, id in enumerate(surface_idx):\n",
    "    surfaceType = lines_full[id].replace('@', '')\n",
    "    print(index, id)\n",
    "    if index < len(surface_idx) - 1:\n",
    "        end_of_surface = surface_idx[index+1]\n",
    "    else:\n",
    "        end_of_surface = len(lines_full)\n",
    "\n",
    "    # Extract the text content for the current surface designation\n",
    "    surface_content = lines_full[id+1:end_of_surface]\n",
    "\n",
    "    # Print the surface type and its content\n",
    "    print(f\"Surface Type: {surfaceType}\")\n",
    "    # print(\"Content:\")\n",
    "    # print('\\n'.join(surface_content))\n",
    "    print('---')\n",
    "\n",
    "    # Extract column number, line numbers, and words for each surface content\n",
    "    for line in surface_content:\n",
    "        columnNum = None\n",
    "        lineNum = None\n",
    "        words = []\n",
    "\n",
    "        # Check if the line contains a column number\n",
    "        if '@column' in line:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    columnNum = int(parts[1])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            print(f\"Column Number: {columnNum}\")\n",
    "            print('---')\n",
    "            continue  # Skip processing the line with @column\n",
    "\n",
    "        # Check if the line contains a line number\n",
    "        if '.' in line:\n",
    "            parts = line.split('.')\n",
    "            if len(parts) >= 2:\n",
    "                lineNum = parts[0].strip()\n",
    "\n",
    "        # Tokenize the words in the line\n",
    "        if lineNum:\n",
    "            words = parts[1].strip().split()\n",
    "        else:\n",
    "            words = line.strip().split()\n",
    "\n",
    "        # Print the extracted information for each line\n",
    "        print(f\"Line Number: {lineNum}\")\n",
    "        print(f\"Words: {words}\")\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nl8Qq9wbPIXy",
    "outputId": "2a175e05-c3a0-4eb1-acc1-5af7e85ec0bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pnum': 'P225104', 'textID': 'TIM 10, 134', 'surface': [{'surfaceType': 'obverse', 'columns': [{'columnNum': 1, 'text': [{'lineNum': '1', 'words': ['dub-sar', 'hu-ru']}, {'lineNum': '2', 'words': ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e-ne']}, {'lineNum': '3', 'words': ['dub-sar', 'hu-ru']}, {'lineNum': '4', 'words': ['a-ga-asz-gi4-gi4-me!(|ME+ASZ|)-e#-ne']}]}]}, {'surfaceType': 'reverse', 'columns': [{'columnNum': 1, 'text': [{'lineNum': '1', 'words': ['igi-bi', '3(disz)', '3(asz)', '6(disz)']}]}]}]}\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "# Combine the surfaces and metadata into one dictionary\n",
    "\n",
    "output = {\n",
    "    \"pnum\": pnum,\n",
    "    \"textID\": textID,\n",
    "    \"surface\": []\n",
    "}\n",
    "\n",
    "for index, id in enumerate(surface_idx):\n",
    "    surfaceType = lines_full[id].replace('@', '')\n",
    "    surface = {\n",
    "        \"surfaceType\": surfaceType,\n",
    "        \"columns\": []\n",
    "    }\n",
    "\n",
    "    if index < len(surface_idx) - 1:\n",
    "        end_of_surface = surface_idx[index+1]\n",
    "    else:\n",
    "        end_of_surface = len(lines_full)\n",
    "\n",
    "    # Extract the text content for the current surface designation\n",
    "    surface_content = lines_full[id+1:end_of_surface]\n",
    "\n",
    "    # Extract column number, line numbers, and words for each surface content\n",
    "    columnNum = None\n",
    "    column = {\n",
    "        \"columnNum\": None,\n",
    "        \"text\": []\n",
    "    }\n",
    "    for line in surface_content:\n",
    "        lineNum = None\n",
    "        words = []\n",
    "\n",
    "        # Check if the line contains a column number\n",
    "        if '@column' in line:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                try:\n",
    "                    columnNum = int(parts[1])\n",
    "                    column[\"columnNum\"] = columnNum\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            continue  # Skip processing the line with @column\n",
    "\n",
    "        # Check if the line contains a line number\n",
    "        if '.' in line:\n",
    "            parts = line.split('.')\n",
    "            if len(parts) >= 2:\n",
    "                lineNum = parts[0].strip()\n",
    "\n",
    "        # Tokenize the words in the line\n",
    "        if lineNum:\n",
    "            words = parts[1].strip().split()\n",
    "        else:\n",
    "            words = line.strip().split()\n",
    "\n",
    "        # Add the line information to the column\n",
    "        line_info = {\n",
    "            \"lineNum\": lineNum,\n",
    "            \"words\": words\n",
    "        }\n",
    "        column[\"text\"].append(line_info)\n",
    "\n",
    "    # Add the column to the surface\n",
    "    surface[\"columns\"].append(column)\n",
    "\n",
    "    # Add the surface to the output\n",
    "    output[\"surface\"].append(surface)\n",
    "\n",
    "# Print the output in the specified dictionary format\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "plIJDngOZr7z"
   },
   "outputs": [],
   "source": [
    "# Save the output dictionary as a JSON file\n",
    "\n",
    "import json\n",
    "with open(f\"{pnum}.json\", \"w\") as json_file:\n",
    "    json.dump(output, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "ljeV7ovmdyX9"
   },
   "outputs": [],
   "source": [
    "# rewrite the code above into a function\n",
    "def cdli_dict(cdli_text):\n",
    "    result = {}\n",
    "    surface = None\n",
    "    column = None\n",
    "    for line in cdli_text.split(\"\\n\"):\n",
    "        match_pnum = re.match(r\"^P(\\d+) = (.*)$\", line)\n",
    "        match_column = re.match(\"^@column (\\d+)$\", line)\n",
    "        match_text = re.match(\"^(\\d+)\\. (.*)$\", line)\n",
    "        \n",
    "        if match_pnum:\n",
    "            result[\"pnum\"] = match[1]\n",
    "            result[\"textID\"] = match[2]\n",
    "            continue\n",
    "        elif \"@tablet\" in line:\n",
    "            pass\n",
    "        elif \"@obverse\" in line: \n",
    "            surface = \"obverse\"\n",
    "        elif \"@reverse\" in line:\n",
    "            surface = \"reverse\"\n",
    "        elif match_column:\n",
    "            column = int(match_column[1])\n",
    "        elif match_text:\n",
    "            if \"surface\" not in result:\n",
    "                result[\"surface\"] = []\n",
    "            if not any(result_surface[\"surfaceType\"] == surface for result_surface in result[\"surface\"]):\n",
    "                result[\"surface\"].append = {\n",
    "                    \"surfaceType\": surface,\n",
    "                    \"columns\": []\n",
    "                }\n",
    "            if not any(surface_column[\"columnNum\"] == column for surface_column in result_surface[\"columns\"] for result_surface in result[\"surface\"]):\n",
    "                result[\"surface\"]\n",
    "            ... # TODO\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4bi04iRXBB9"
   },
   "source": [
    "## Egyptian Example 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e6CfHB0KNVaf"
   },
   "outputs": [],
   "source": [
    "eg2_csv = \"\"\",text,line,word,ref,frag,norm,unicode_word,unicode,lemma_id,cf,pos,sense\n",
    "92,3Z5EM77HJFCOPKZDDZFEMI6KVY,5,7,3Z5EM77HJFCOPKZDDZFEMI6KVY.5.7,gꜣu̯.w,gꜣu̯.w,<g>V96</g>𓅱,\"['<', 'g', '>', 'V', '9', '6', '<', '/', 'g', '>', '𓅱']\",166210,gꜣu̯,VERB,eng sein; entbehren; (jmdn.) Not leiden lassen\n",
    "151,4WVXFJZFLNAYHP3Y5O5SLWD7DA,2,2,4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.2,nꜥw,nꜥw,𓈖𓂝𓅱<g>I14C</g>𓏤,\"['𓈖', '𓂝', '𓅱', '<', 'g', '>', 'I', '1', '4', 'C', '<', '/', 'g', '>', '𓏤']\",80510,Nꜥw,PROPN,Sich windender (Personifikation der Schlange)\n",
    "153,4WVXFJZFLNAYHP3Y5O5SLWD7DA,2,5,4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.5,nꜥw,nꜥw,𓈖𓂝𓅱<g>I14C</g>𓏤,\"['𓈖', '𓂝', '𓅱', '<', 'g', '>', 'I', '1', '4', 'C', '<', '/', 'g', '>', '𓏤']\",80510,Nꜥw,PROPN,Sich windender (Personifikation der Schlange)\n",
    "200,67HZI45S3REA3LWVZOKJ6QJOIE,14,9,67HZI45S3REA3LWVZOKJ6QJOIE.14.9,nbi̯.n,nbi̯.n,𓈖𓎟𓃀<g>D107</g>𓈖,\"['𓈖', '𓎟', '𓃀', '<', 'g', '>', 'D', '1', '0', '7', '<', '/', 'g', '>', '𓈖']\",82520,nbi̯,VERB,schmelzen; gießen\n",
    "204,67HZI45S3REA3LWVZOKJ6QJOIE,14,13,67HZI45S3REA3LWVZOKJ6QJOIE.14.13,nḏr.n,nḏr.n,𓈖𓇦𓂋<g>U19A</g>𓆱𓈖,\"['𓈖', '𓇦', '𓂋', '<', 'g', '>', 'U', '1', '9', 'A', '<', '/', 'g', '>', '𓆱', '𓈖']\",91630,nḏr,VERB,(Holz) bearbeiten; zimmern\n",
    "206,67HZI45S3REA3LWVZOKJ6QJOIE,14,15,67HZI45S3REA3LWVZOKJ6QJOIE.14.15,b(w)n.wDU,bwn.wDU,𓃀𓈖𓏌𓅱<g>T86</g><g>T86</g>,\"['𓃀', '𓈖', '𓏌', '𓅱', '<', 'g', '>', 'T', '8', '6', '<', '/', 'g', '>', '<', 'g', '>', 'T', '8', '6', '<', '/', 'g', '>']\",55330,bwn,NOUN,Speerspitzen (des Fischspeeres)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "kcooRFH-XQE3",
    "outputId": "fdf0a3b0-7aec-4ee0-91fa-7f930f589f9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  [V96, 𓅱]\n",
       "1        [𓈖, 𓂝, 𓅱, I14C, 𓏤]\n",
       "2        [𓈖, 𓂝, 𓅱, I14C, 𓏤]\n",
       "3        [𓈖, 𓎟, 𓃀, D107, 𓈖]\n",
       "4     [𓈖, 𓇦, 𓂋, U19A, 𓆱, 𓈖]\n",
       "5    [𓃀, 𓈖, 𓏌, 𓅱, T86, T86]\n",
       "Name: unicode_word, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Convert the string into a StringIO object\n",
    "# This is only necessary because we presented the csv as a string instead of loading it as a file\n",
    "csv_data = StringIO(eg2_csv)\n",
    "\n",
    "# Read the data into a pandas DataFrame\n",
    "df = pd.read_csv(csv_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df[\"unicode_word\"].apply(lambda x: [glyph.lstrip(\"<g>\").rstrip(\"</g>\") for glyph in re.findall(r\"<g>.*?</g>|.\", x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "r1I_-P_wXXdl"
   },
   "outputs": [],
   "source": [
    "def split_tags(text):\n",
    "    parts = []  # List to collect output of the function\n",
    "    while '<g>' in text and '</g>' in text:\n",
    "        pre, rest = text.split('<g>', 1)  # splits at the first <g> found\n",
    "        tag_content, post = rest.split('</g>', 1)  # splits the rest at the first </g> found\n",
    "\n",
    "        # adds elements before the first <g></g> tag to the List\n",
    "        parts.extend(pre)\n",
    "\n",
    "        #  adds element inside the first <g></g> tag to the List\n",
    "        parts.append(tag_content)\n",
    "\n",
    "        # text variable is set to remaining text\n",
    "        text = post\n",
    "\n",
    "    # After last tag found, the remainder of the text is split and added to the List\n",
    "    parts.extend(text)\n",
    "    return parts\n",
    "\n",
    "def process_text(text):\n",
    "    if pd.isna(text): # deals with NaN\n",
    "        return []\n",
    "    else:\n",
    "        return split_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "AucimHYGXmvD",
    "outputId": "2c67b9d5-534d-459e-a1b8-f8c013b4baf9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>line</th>\n",
       "      <th>word</th>\n",
       "      <th>ref</th>\n",
       "      <th>frag</th>\n",
       "      <th>norm</th>\n",
       "      <th>unicode_word</th>\n",
       "      <th>lemma_id</th>\n",
       "      <th>cf</th>\n",
       "      <th>pos</th>\n",
       "      <th>sense</th>\n",
       "      <th>unicode_splitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92</td>\n",
       "      <td>3Z5EM77HJFCOPKZDDZFEMI6KVY</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3Z5EM77HJFCOPKZDDZFEMI6KVY.5.7</td>\n",
       "      <td>gꜣu̯.w</td>\n",
       "      <td>gꜣu̯.w</td>\n",
       "      <td>&lt;g&gt;V96&lt;/g&gt;𓅱</td>\n",
       "      <td>166210</td>\n",
       "      <td>gꜣu̯</td>\n",
       "      <td>VERB</td>\n",
       "      <td>eng sein; entbehren; (jmdn.) Not leiden lassen</td>\n",
       "      <td>[V96, 𓅱]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151</td>\n",
       "      <td>4WVXFJZFLNAYHP3Y5O5SLWD7DA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.2</td>\n",
       "      <td>nꜥw</td>\n",
       "      <td>nꜥw</td>\n",
       "      <td>𓈖𓂝𓅱&lt;g&gt;I14C&lt;/g&gt;𓏤</td>\n",
       "      <td>80510</td>\n",
       "      <td>Nꜥw</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Sich windender (Personifikation der Schlange)</td>\n",
       "      <td>[𓈖, 𓂝, 𓅱, I14C, 𓏤]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>4WVXFJZFLNAYHP3Y5O5SLWD7DA</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.5</td>\n",
       "      <td>nꜥw</td>\n",
       "      <td>nꜥw</td>\n",
       "      <td>𓈖𓂝𓅱&lt;g&gt;I14C&lt;/g&gt;𓏤</td>\n",
       "      <td>80510</td>\n",
       "      <td>Nꜥw</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>Sich windender (Personifikation der Schlange)</td>\n",
       "      <td>[𓈖, 𓂝, 𓅱, I14C, 𓏤]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>67HZI45S3REA3LWVZOKJ6QJOIE</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>67HZI45S3REA3LWVZOKJ6QJOIE.14.9</td>\n",
       "      <td>nbi̯.n</td>\n",
       "      <td>nbi̯.n</td>\n",
       "      <td>𓈖𓎟𓃀&lt;g&gt;D107&lt;/g&gt;𓈖</td>\n",
       "      <td>82520</td>\n",
       "      <td>nbi̯</td>\n",
       "      <td>VERB</td>\n",
       "      <td>schmelzen; gießen</td>\n",
       "      <td>[𓈖, 𓎟, 𓃀, D107, 𓈖]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204</td>\n",
       "      <td>67HZI45S3REA3LWVZOKJ6QJOIE</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>67HZI45S3REA3LWVZOKJ6QJOIE.14.13</td>\n",
       "      <td>nḏr.n</td>\n",
       "      <td>nḏr.n</td>\n",
       "      <td>𓈖𓇦𓂋&lt;g&gt;U19A&lt;/g&gt;𓆱𓈖</td>\n",
       "      <td>91630</td>\n",
       "      <td>nḏr</td>\n",
       "      <td>VERB</td>\n",
       "      <td>(Holz) bearbeiten; zimmern</td>\n",
       "      <td>[𓈖, 𓇦, 𓂋, U19A, 𓆱, 𓈖]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>206</td>\n",
       "      <td>67HZI45S3REA3LWVZOKJ6QJOIE</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>67HZI45S3REA3LWVZOKJ6QJOIE.14.15</td>\n",
       "      <td>b(w)n.wDU</td>\n",
       "      <td>bwn.wDU</td>\n",
       "      <td>𓃀𓈖𓏌𓅱&lt;g&gt;T86&lt;/g&gt;&lt;g&gt;T86&lt;/g&gt;</td>\n",
       "      <td>55330</td>\n",
       "      <td>bwn</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>Speerspitzen (des Fischspeeres)</td>\n",
       "      <td>[𓃀, 𓈖, 𓏌, 𓅱, T86, T86]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                        text  line  word  \\\n",
       "0          92  3Z5EM77HJFCOPKZDDZFEMI6KVY     5     7   \n",
       "1         151  4WVXFJZFLNAYHP3Y5O5SLWD7DA     2     2   \n",
       "2         153  4WVXFJZFLNAYHP3Y5O5SLWD7DA     2     5   \n",
       "3         200  67HZI45S3REA3LWVZOKJ6QJOIE    14     9   \n",
       "4         204  67HZI45S3REA3LWVZOKJ6QJOIE    14    13   \n",
       "5         206  67HZI45S3REA3LWVZOKJ6QJOIE    14    15   \n",
       "\n",
       "                                ref       frag     norm  \\\n",
       "0    3Z5EM77HJFCOPKZDDZFEMI6KVY.5.7     gꜣu̯.w   gꜣu̯.w   \n",
       "1    4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.2        nꜥw      nꜥw   \n",
       "2    4WVXFJZFLNAYHP3Y5O5SLWD7DA.2.5        nꜥw      nꜥw   \n",
       "3   67HZI45S3REA3LWVZOKJ6QJOIE.14.9     nbi̯.n   nbi̯.n   \n",
       "4  67HZI45S3REA3LWVZOKJ6QJOIE.14.13      nḏr.n    nḏr.n   \n",
       "5  67HZI45S3REA3LWVZOKJ6QJOIE.14.15  b(w)n.wDU  bwn.wDU   \n",
       "\n",
       "               unicode_word  lemma_id    cf    pos  \\\n",
       "0               <g>V96</g>𓅱    166210  gꜣu̯   VERB   \n",
       "1           𓈖𓂝𓅱<g>I14C</g>𓏤     80510   Nꜥw  PROPN   \n",
       "2           𓈖𓂝𓅱<g>I14C</g>𓏤     80510   Nꜥw  PROPN   \n",
       "3           𓈖𓎟𓃀<g>D107</g>𓈖     82520  nbi̯   VERB   \n",
       "4          𓈖𓇦𓂋<g>U19A</g>𓆱𓈖     91630   nḏr   VERB   \n",
       "5  𓃀𓈖𓏌𓅱<g>T86</g><g>T86</g>     55330   bwn   NOUN   \n",
       "\n",
       "                                            sense        unicode_splitted  \n",
       "0  eng sein; entbehren; (jmdn.) Not leiden lassen                [V96, 𓅱]  \n",
       "1   Sich windender (Personifikation der Schlange)      [𓈖, 𓂝, 𓅱, I14C, 𓏤]  \n",
       "2   Sich windender (Personifikation der Schlange)      [𓈖, 𓂝, 𓅱, I14C, 𓏤]  \n",
       "3                               schmelzen; gießen      [𓈖, 𓎟, 𓃀, D107, 𓈖]  \n",
       "4                      (Holz) bearbeiten; zimmern   [𓈖, 𓇦, 𓂋, U19A, 𓆱, 𓈖]  \n",
       "5                 Speerspitzen (des Fischspeeres)  [𓃀, 𓈖, 𓏌, 𓅱, T86, T86]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply functions to every row of the column 'unicode_word'\n",
    "df['unicode_splitted'] = df['unicode_word'].apply(process_text)\n",
    "# delete obsolete column\n",
    "df.drop('unicode', axis=1, inplace=True)\n",
    "\n",
    "# show modified dataframe\n",
    "df\n",
    "# export as *.csv file\n",
    "#df.to_csv(\"EG-TLA-example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xscuwIbxYGJV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAHFgXUIe4Ta"
   },
   "source": [
    "## Egyptian Example 2:\n",
    "A sentence from the sarcophagus of the Napatan king Aspelta (c. 600-580 BCE), found in his pyramid in Nuri, Sudan (Nu. 8), https://collections.mfa.org/objects/145117\n",
    "\n",
    "Get the context of the sentence from the Thesaurus Linguae Aegyptiae: https://thesaurus-linguae-aegyptiae.de/text/27KHHMEP4VHSDH737F2OFLKNSE/sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hRS239AKaLty",
    "outputId": "2774ea10-73a7-4195-cab3-87349be63a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'publication_statement': {'credit_citation': 'Doris Topmann, Sentence ID 2CBOF5UQ7JGETCXG2CQKPCWDZM <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data/blob/v17/sentences/2CBOF5UQ7JGETCXG2CQKPCWDZM.json>, in: Thesaurus Linguae Aegyptiae: Raw Data <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data>, Corpus issue 17 (31 October 2022), ed. by Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig (first published: 22 September 2023)', 'collection_editors': 'Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig', 'data_engineers': {'input_software_BTS': ['Christoph Plutte', 'Jakob Höper'], 'database_curation': ['Simon D. Schweitzer'], 'data_transformation': ['Jakob Höper', 'R. Dominik Blöse', 'Daniel A. Werning']}, 'date_published_in_TLA': '2022-10-31', 'rawdata_first_published': '2023-09-22', 'corresponding_TLA_URL': 'https://thesaurus-linguae-aegyptiae.de/sentence/2CBOF5UQ7JGETCXG2CQKPCWDZM', 'license': 'Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) <https://creativecommons.org/licenses/by-sa/4.0/>'}, 'context': {'line': 'III', 'paragraph': None, 'pos': 7, 'textId': '27KHHMEP4VHSDH737F2OFLKNSE', 'textType': 'Text', 'variants': 1}, 'eclass': 'BTSSentence', 'glyphs': {'mdc_compact': None, 'unicode': None}, 'id': '2CBOF5UQ7JGETCXG2CQKPCWDZM', 'relations': {'contains': [{'eclass': 'BTSAnnotation', 'id': 'DYJEAXFKBJAXJPVLJGWREJZJ5M', 'ranges': [{'end': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'start': '22TFIMS2CBBCFFCDSCAIT3HR3Y'}], 'type': 'ägyptologische Textsegmentierung'}], 'partOf': [{'eclass': 'BTSText', 'id': '27KHHMEP4VHSDH737F2OFLKNSE', 'name': 'Isis (HT 15, HT 14, HT 17)', 'type': 'Text'}]}, 'tokens': [{'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'PTCL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D35:N35', 'mdc_original': 'D35-N35', 'mdc_original_safe': None, 'mdc_tla': 'D35-N35', 'order': [1, 2], 'unicode': '𓂜𓈖'}, 'id': '22TFIMS2CBBCFFCDSCAIT3HR3Y', 'label': 'nn', 'lemma': {'POS': {'type': 'particle'}, 'id': '851961'}, 'transcription': {'mdc': 'nn', 'unicode': 'nn'}, 'translations': {'de': ['[Negationspartikel]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'SC.act.ngem.nom.subj_Neg.nn', 'lingGloss': 'V\\\\tam.act', 'numeric': 210020}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'W11-V28-A7', 'mdc_original': 'W11-V28-A7', 'mdc_original_safe': None, 'mdc_tla': 'W11-V28-A7', 'order': [2, 3, 4], 'unicode': '𓎼𓎛𓀉'}, 'id': 'IOLUGQXLCRGNLMTAPJ65LI7MHU', 'label': 'gḥ', 'lemma': {'POS': {'subtype': 'verb_3-lit', 'type': 'verb'}, 'id': '166480'}, 'transcription': {'mdc': 'gH', 'unicode': 'gḥ'}, 'translations': {'de': ['matt sein']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'Noun.pl.stpr.3sgm', 'lingGloss': 'N.f:pl:stpr', 'numeric': 70154}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D36:X1*F51B-Z2', 'mdc_original': 'D36-X1-F51B-Z2', 'mdc_original_safe': None, 'mdc_tla': 'D36-X1-F51B-Z2', 'order': [5, 6, 7, 8], 'unicode': '𓂝𓏏𓄹︀\\U00013440𓏥'}, 'id': 'GUVBJUGCSVF5VN55PN6RYS4YLI', 'label': 'ꜥ,t.pl', 'lemma': {'POS': {'subtype': 'substantive_fem', 'type': 'substantive'}, 'id': '34550'}, 'transcription': {'mdc': 'a.t.PL', 'unicode': 'ꜥ.t.PL'}, 'translations': {'de': ['Glied; Körperteil']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': '-3sg.m', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'I9', 'mdc_original': 'I9', 'mdc_original_safe': None, 'mdc_tla': 'I9', 'order': [9], 'unicode': '𓆑'}, 'id': 'GIHCJ27JXVAM7GDUYWGEPKBRB4', 'label': '=f', 'lemma': {'POS': {'subtype': 'personal_pronoun', 'type': 'pronoun'}, 'id': '10050'}, 'transcription': {'mdc': '=f', 'unicode': '=f'}, 'translations': {'de': ['[Suffix Pron. sg.3.m.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'dem.f.pl', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M17-Q3:N35', 'mdc_original': 'M17-Q3-N35', 'mdc_original_safe': None, 'mdc_tla': 'M17-Q3-N35', 'order': [10, 11, 12], 'unicode': '𓇋𓊪𓈖'}, 'id': 'Z6HTGGPBPRDT3OZTZNXRF2GRDA', 'label': 'jp〈t〉n', 'lemma': {'POS': {'subtype': 'demonstrative_pronoun', 'type': 'pronoun'}, 'id': '850009'}, 'transcription': {'mdc': 'jp〈t〉n', 'unicode': 'jp〈t〉n'}, 'translations': {'de': ['diese [Dem.Pron. pl.f.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'D4-Q1-A40', 'mdc_original': 'D4-Q1-A40', 'mdc_original_safe': None, 'mdc_tla': 'D4-Q1-A40', 'order': [13, 14, 15], 'unicode': '𓁹𓊨𓀭'}, 'id': 'UCFJWBLRKJG4NJWTWT22WDR2MU', 'label': 'Wsr,w', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '49461'}, 'transcription': {'mdc': 'wsr.w', 'unicode': 'Wsr.w'}, 'translations': {'de': ['Osiris (Totentitel des Verstorbenen)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M23-X1:N35', 'mdc_original': 'M23-X1-N35', 'mdc_original_safe': None, 'mdc_tla': 'M23-X1-N35', 'order': [16, 17, 18], 'unicode': '𓇓𓏏𓈖'}, 'id': 'LI5FJI4ZUJEMPIKS5RQ5HHNBUE', 'label': 'nzw', 'lemma': {'POS': {'type': 'substantive'}, 'id': '88040'}, 'transcription': {'mdc': 'nzw', 'unicode': 'nzw'}, 'translations': {'de': ['König']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:N17-N17', 'mdc_original': 'V30-N17-N17', 'mdc_original_safe': None, 'mdc_tla': 'V30-N17-N17', 'order': [19, 20, 21], 'unicode': '𓎟𓇿𓇿'}, 'id': 'ICADWHGbHkfdokpooG4eCy3Zfe8', 'label': 'nb-Tꜣ,du', 'lemma': {'POS': {'subtype': 'epith_king', 'type': 'epitheton_title'}, 'id': '400038'}, 'transcription': {'mdc': 'nb-tA.DU', 'unicode': 'nb-Tꜣ.DU'}, 'translations': {'de': ['Herr der Beiden Länder (Könige)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:D4-Aa1*X1:Y1', 'mdc_original': 'V30-D4-Aa1-X1-Y1', 'mdc_original_safe': None, 'mdc_tla': 'V30-D4-Aa1-X1-Y1', 'order': [22, 23, 24, 25, 26], 'unicode': '𓎟𓁹𓐍𓏏𓏛'}, 'id': 'ICADWHT2O1dc30SXuRZUlquIDpM', 'label': 'nb-jr(,t)-(j)ḫ,t', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '400354'}, 'transcription': {'mdc': 'nb-jr(.t)-(j)x.t', 'unicode': 'nb-jr(.t)-(j)ḫ.t'}, 'translations': {'de': ['Herr des Rituals']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': '<-M17-O34:Q3-E23-N17->', 'mdc_original': '<-M17-O34-Q3-E23-N17->', 'mdc_original_safe': None, 'mdc_tla': '<-M17-O34-Q3-E23-N17->', 'order': [18, 19, 20, 21, 22, 23], 'unicode': '𓍹\\U0001343c𓇋𓊃𓊪𓃭𓇿\\U0001343d𓍺'}, 'id': 'J3MLYALWVNAMDDG33VZ3RIEEUA', 'label': 'Jsplt', 'lemma': {'POS': {'subtype': 'kings_name', 'type': 'entity_name'}, 'id': '850103'}, 'transcription': {'mdc': 'jsplt', 'unicode': 'Jsplt'}, 'translations': {'de': ['Aspelta']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N.m:sg', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'U5:D36-P8h', 'mdc_original': 'U5-D36-P8h', 'mdc_original_safe': None, 'mdc_tla': 'U5-D36-P8h', 'order': [25, 26, 27], 'unicode': '𓌷𓂝𓊤︂'}, 'id': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'label': 'mꜣꜥ-ḫrw', 'lemma': {'POS': {'subtype': 'substantive_masc', 'type': 'substantive'}, 'id': '66750'}, 'transcription': {'mdc': 'mAa-xrw', 'unicode': 'mꜣꜥ-ḫrw'}, 'translations': {'de': ['Gerechtfertigter (der selige Tote)']}, 'type': 'word'}], 'transcription': {'mdc': 'nn gH a.t.PL=f jp〈t〉n wsr.w nzw nb-tA.DU nb-jr(.t)-(j)x.t jsplt mAa-xrw', 'unicode': 'nn gḥ ꜥ.t.PL=f jp〈t〉n Wsr.w nzw nb-Tꜣ.DU nb-jr(.t)-(j)ḫ.t Jsplt mꜣꜥ-ḫrw'}, 'translations': {'de': ['Diese seine Glieder werden nicht matt sein, (die des) Osiris Königs, des Herrn der Beiden Länder, des Herrn des Rituals, Aspelta, des Gerechtfertigten.']}, 'type': None, 'wordCount': 11, 'editors': {'author': 'Doris Topmann', 'contributors': None, 'created': '2020-12-23 12:24:26', 'type': None, 'updated': '2022-08-29 10:22:01'}}\n"
     ]
    }
   ],
   "source": [
    "# This Dictionary was created from the original json file\n",
    "\n",
    "eg1 = {'publication_statement': {'credit_citation': 'Doris Topmann, Sentence ID 2CBOF5UQ7JGETCXG2CQKPCWDZM <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data/blob/v17/sentences/2CBOF5UQ7JGETCXG2CQKPCWDZM.json>, in: Thesaurus Linguae Aegyptiae: Raw Data <https://github.com/thesaurus-linguae-aegyptiae/tla-raw-data>, Corpus issue 17 (31 October 2022), ed. by Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig (first published: 22 September 2023)', 'collection_editors': 'Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig', 'data_engineers': {'input_software_BTS': ['Christoph Plutte', 'Jakob Höper'], 'database_curation': ['Simon D. Schweitzer'], 'data_transformation': ['Jakob Höper', 'R. Dominik Blöse', 'Daniel A. Werning']}, 'date_published_in_TLA': '2022-10-31', 'rawdata_first_published': '2023-09-22', 'corresponding_TLA_URL': 'https://thesaurus-linguae-aegyptiae.de/sentence/2CBOF5UQ7JGETCXG2CQKPCWDZM', 'license': 'Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) <https://creativecommons.org/licenses/by-sa/4.0/>'}, 'context': {'line': 'III', 'paragraph': None, 'pos': 7, 'textId': '27KHHMEP4VHSDH737F2OFLKNSE', 'textType': 'Text', 'variants': 1}, 'eclass': 'BTSSentence', 'glyphs': {'mdc_compact': None, 'unicode': None}, 'id': '2CBOF5UQ7JGETCXG2CQKPCWDZM', 'relations': {'contains': [{'eclass': 'BTSAnnotation', 'id': 'DYJEAXFKBJAXJPVLJGWREJZJ5M', 'ranges': [{'end': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'start': '22TFIMS2CBBCFFCDSCAIT3HR3Y'}], 'type': 'ägyptologische Textsegmentierung'}], 'partOf': [{'eclass': 'BTSText', 'id': '27KHHMEP4VHSDH737F2OFLKNSE', 'name': 'Isis (HT 15, HT 14, HT 17)', 'type': 'Text'}]}, 'tokens': [{'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'PTCL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D35:N35', 'mdc_original': 'D35-N35', 'mdc_original_safe': None, 'mdc_tla': 'D35-N35', 'order': [1, 2], 'unicode': '𓂜𓈖'}, 'id': '22TFIMS2CBBCFFCDSCAIT3HR3Y', 'label': 'nn', 'lemma': {'POS': {'type': 'particle'}, 'id': '851961'}, 'transcription': {'mdc': 'nn', 'unicode': 'nn'}, 'translations': {'de': ['[Negationspartikel]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'SC.act.ngem.nom.subj_Neg.nn', 'lingGloss': 'V\\\\tam.act', 'numeric': 210020}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'W11-V28-A7', 'mdc_original': 'W11-V28-A7', 'mdc_original_safe': None, 'mdc_tla': 'W11-V28-A7', 'order': [2, 3, 4], 'unicode': '𓎼𓎛𓀉'}, 'id': 'IOLUGQXLCRGNLMTAPJ65LI7MHU', 'label': 'gḥ', 'lemma': {'POS': {'subtype': 'verb_3-lit', 'type': 'verb'}, 'id': '166480'}, 'transcription': {'mdc': 'gH', 'unicode': 'gḥ'}, 'translations': {'de': ['matt sein']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': 'Noun.pl.stpr.3sgm', 'lingGloss': 'N.f:pl:stpr', 'numeric': 70154}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'D36:X1*F51B-Z2', 'mdc_original': 'D36-X1-F51B-Z2', 'mdc_original_safe': None, 'mdc_tla': 'D36-X1-F51B-Z2', 'order': [5, 6, 7, 8], 'unicode': '𓂝𓏏𓄹︀\\U00013440𓏥'}, 'id': 'GUVBJUGCSVF5VN55PN6RYS4YLI', 'label': 'ꜥ,t.pl', 'lemma': {'POS': {'subtype': 'substantive_fem', 'type': 'substantive'}, 'id': '34550'}, 'transcription': {'mdc': 'a.t.PL', 'unicode': 'ꜥ.t.PL'}, 'translations': {'de': ['Glied; Körperteil']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': '-3sg.m', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'I9', 'mdc_original': 'I9', 'mdc_original_safe': None, 'mdc_tla': 'I9', 'order': [9], 'unicode': '𓆑'}, 'id': 'GIHCJ27JXVAM7GDUYWGEPKBRB4', 'label': '=f', 'lemma': {'POS': {'subtype': 'personal_pronoun', 'type': 'pronoun'}, 'id': '10050'}, 'transcription': {'mdc': '=f', 'unicode': '=f'}, 'translations': {'de': ['[Suffix Pron. sg.3.m.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'dem.f.pl', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M17-Q3:N35', 'mdc_original': 'M17-Q3-N35', 'mdc_original_safe': None, 'mdc_tla': 'M17-Q3-N35', 'order': [10, 11, 12], 'unicode': '𓇋𓊪𓈖'}, 'id': 'Z6HTGGPBPRDT3OZTZNXRF2GRDA', 'label': 'jp〈t〉n', 'lemma': {'POS': {'subtype': 'demonstrative_pronoun', 'type': 'pronoun'}, 'id': '850009'}, 'transcription': {'mdc': 'jp〈t〉n', 'unicode': 'jp〈t〉n'}, 'translations': {'de': ['diese [Dem.Pron. pl.f.]']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': False, 'mdc_compact': 'D4-Q1-A40', 'mdc_original': 'D4-Q1-A40', 'mdc_original_safe': None, 'mdc_tla': 'D4-Q1-A40', 'order': [13, 14, 15], 'unicode': '𓁹𓊨𓀭'}, 'id': 'UCFJWBLRKJG4NJWTWT22WDR2MU', 'label': 'Wsr,w', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '49461'}, 'transcription': {'mdc': 'wsr.w', 'unicode': 'Wsr.w'}, 'translations': {'de': ['Osiris (Totentitel des Verstorbenen)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'M23-X1:N35', 'mdc_original': 'M23-X1-N35', 'mdc_original_safe': None, 'mdc_tla': 'M23-X1-N35', 'order': [16, 17, 18], 'unicode': '𓇓𓏏𓈖'}, 'id': 'LI5FJI4ZUJEMPIKS5RQ5HHNBUE', 'label': 'nzw', 'lemma': {'POS': {'type': 'substantive'}, 'id': '88040'}, 'transcription': {'mdc': 'nzw', 'unicode': 'nzw'}, 'translations': {'de': ['König']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:N17-N17', 'mdc_original': 'V30-N17-N17', 'mdc_original_safe': None, 'mdc_tla': 'V30-N17-N17', 'order': [19, 20, 21], 'unicode': '𓎟𓇿𓇿'}, 'id': 'ICADWHGbHkfdokpooG4eCy3Zfe8', 'label': 'nb-Tꜣ,du', 'lemma': {'POS': {'subtype': 'epith_king', 'type': 'epitheton_title'}, 'id': '400038'}, 'transcription': {'mdc': 'nb-tA.DU', 'unicode': 'nb-Tꜣ.DU'}, 'translations': {'de': ['Herr der Beiden Länder (Könige)']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'TITL', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'V30:D4-Aa1*X1:Y1', 'mdc_original': 'V30-D4-Aa1-X1-Y1', 'mdc_original_safe': None, 'mdc_tla': 'V30-D4-Aa1-X1-Y1', 'order': [22, 23, 24, 25, 26], 'unicode': '𓎟𓁹𓐍𓏏𓏛'}, 'id': 'ICADWHT2O1dc30SXuRZUlquIDpM', 'label': 'nb-jr(,t)-(j)ḫ,t', 'lemma': {'POS': {'subtype': 'title', 'type': 'epitheton_title'}, 'id': '400354'}, 'transcription': {'mdc': 'nb-jr(.t)-(j)x.t', 'unicode': 'nb-jr(.t)-(j)ḫ.t'}, 'translations': {'de': ['Herr des Rituals']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'ROYLN', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': '<-M17-O34:Q3-E23-N17->', 'mdc_original': '<-M17-O34-Q3-E23-N17->', 'mdc_original_safe': None, 'mdc_tla': '<-M17-O34-Q3-E23-N17->', 'order': [18, 19, 20, 21, 22, 23], 'unicode': '𓍹\\U0001343c𓇋𓊃𓊪𓃭𓇿\\U0001343d𓍺'}, 'id': 'J3MLYALWVNAMDDG33VZ3RIEEUA', 'label': 'Jsplt', 'lemma': {'POS': {'subtype': 'kings_name', 'type': 'entity_name'}, 'id': '850103'}, 'transcription': {'mdc': 'jsplt', 'unicode': 'Jsplt'}, 'translations': {'de': ['Aspelta']}, 'type': 'word'}, {'annoTypes': ['ägyptologische Textsegmentierung'], 'flexion': {'btsGloss': '(unspecified)', 'lingGloss': 'N.m:sg', 'numeric': 3}, 'glyphs': {'mdc_artificially_aligned': True, 'mdc_compact': 'U5:D36-P8h', 'mdc_original': 'U5-D36-P8h', 'mdc_original_safe': None, 'mdc_tla': 'U5-D36-P8h', 'order': [25, 26, 27], 'unicode': '𓌷𓂝𓊤︂'}, 'id': 'OKLGJLCEQFHU7HDRYUTYR352YA', 'label': 'mꜣꜥ-ḫrw', 'lemma': {'POS': {'subtype': 'substantive_masc', 'type': 'substantive'}, 'id': '66750'}, 'transcription': {'mdc': 'mAa-xrw', 'unicode': 'mꜣꜥ-ḫrw'}, 'translations': {'de': ['Gerechtfertigter (der selige Tote)']}, 'type': 'word'}], 'transcription': {'mdc': 'nn gH a.t.PL=f jp〈t〉n wsr.w nzw nb-tA.DU nb-jr(.t)-(j)x.t jsplt mAa-xrw', 'unicode': 'nn gḥ ꜥ.t.PL=f jp〈t〉n Wsr.w nzw nb-Tꜣ.DU nb-jr(.t)-(j)ḫ.t Jsplt mꜣꜥ-ḫrw'}, 'translations': {'de': ['Diese seine Glieder werden nicht matt sein, (die des) Osiris Königs, des Herrn der Beiden Länder, des Herrn des Rituals, Aspelta, des Gerechtfertigten.']}, 'type': None, 'wordCount': 11, 'editors': {'author': 'Doris Topmann', 'contributors': None, 'created': '2020-12-23 12:24:26', 'type': None, 'updated': '2022-08-29 10:22:01'}}\n",
    "print(eg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiFPKKYVukau",
    "outputId": "b6c4ed47-39de-457a-df84-b3c6c6bca130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "𓂜𓈖 nn [Negationspartikel] particle 22TFIMS2CBBCFFCDSCAIT3HR3Y\n",
      "𓎼𓎛𓀉 gḥ matt sein verb IOLUGQXLCRGNLMTAPJ65LI7MHU\n",
      "𓂝𓏏𓄹︀𓑀𓏥 ꜥ.t.PL Glied; Körperteil substantive GUVBJUGCSVF5VN55PN6RYS4YLI\n",
      "𓆑 =f [Suffix Pron. sg.3.m.] pronoun GIHCJ27JXVAM7GDUYWGEPKBRB4\n",
      "𓇋𓊪𓈖 jp〈t〉n diese [Dem.Pron. pl.f.] pronoun Z6HTGGPBPRDT3OZTZNXRF2GRDA\n",
      "𓁹𓊨𓀭 Wsr.w Osiris (Totentitel des Verstorbenen) epitheton_title UCFJWBLRKJG4NJWTWT22WDR2MU\n",
      "𓇓𓏏𓈖 nzw König substantive LI5FJI4ZUJEMPIKS5RQ5HHNBUE\n",
      "𓎟𓇿𓇿 nb-Tꜣ.DU Herr der Beiden Länder (Könige) epitheton_title ICADWHGbHkfdokpooG4eCy3Zfe8\n",
      "𓎟𓁹𓐍𓏏𓏛 nb-jr(.t)-(j)ḫ.t Herr des Rituals epitheton_title ICADWHT2O1dc30SXuRZUlquIDpM\n",
      "𓍹𓐼𓇋𓊃𓊪𓃭𓇿𓐽𓍺 Jsplt Aspelta entity_name J3MLYALWVNAMDDG33VZ3RIEEUA\n",
      "𓌷𓂝𓊤︂ mꜣꜥ-ḫrw Gerechtfertigter (der selige Tote) substantive OKLGJLCEQFHU7HDRYUTYR352YA\n"
     ]
    }
   ],
   "source": [
    "# parse the dictionary (json)\n",
    "\n",
    "unicodeHiero = []\n",
    "transcription = []\n",
    "translLemma = []\n",
    "posLemma = []\n",
    "tokenID = []\n",
    "\n",
    "for text_word in eg1[\"tokens\"] :\n",
    "    print(text_word[\"glyphs\"][\"unicode\"], text_word[\"transcription\"][\"unicode\"], text_word[\"translations\"][\"de\"][0], text_word[\"lemma\"][\"POS\"][\"type\"], text_word[\"id\"] )\n",
    "    tokenID.append(text_word[\"id\"])\n",
    "    unicodeHiero.append(text_word[\"glyphs\"][\"unicode\"])\n",
    "    translLemma.append(text_word[\"translations\"][\"de\"][0])\n",
    "    posLemma.append(text_word[\"lemma\"][\"POS\"][\"type\"])\n",
    "\n",
    "    if text_word[\"transcription\"][\"unicode\"][0] == \"=\" : # replace equal sign as it will cause trouble in spreadsheet software like MS Excel\n",
    "        transcription.append(text_word[\"transcription\"][\"unicode\"].replace(\"=\", '⸗')) # U+2E17\n",
    "    else :\n",
    "        transcription.append(text_word[\"transcription\"][\"unicode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cBVnP7t5uwSH"
   },
   "outputs": [],
   "source": [
    "# get the ID of this sentence\n",
    "\n",
    "sentenceID = eg1[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "meY8DrYSu4cD",
    "outputId": "664d05a9-c0cf-49f2-d078-a9ef3480d584"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unicode_hieroglyphs</th>\n",
       "      <th>unicode_transcription</th>\n",
       "      <th>lemma_translation</th>\n",
       "      <th>part-of-speech</th>\n",
       "      <th>tokenID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>𓂜𓈖</td>\n",
       "      <td>nn</td>\n",
       "      <td>[Negationspartikel]</td>\n",
       "      <td>particle</td>\n",
       "      <td>22TFIMS2CBBCFFCDSCAIT3HR3Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>𓎼𓎛𓀉</td>\n",
       "      <td>gḥ</td>\n",
       "      <td>matt sein</td>\n",
       "      <td>verb</td>\n",
       "      <td>IOLUGQXLCRGNLMTAPJ65LI7MHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>𓂝𓏏𓄹︀𓑀𓏥</td>\n",
       "      <td>ꜥ.t.PL</td>\n",
       "      <td>Glied; Körperteil</td>\n",
       "      <td>substantive</td>\n",
       "      <td>GUVBJUGCSVF5VN55PN6RYS4YLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>𓆑</td>\n",
       "      <td>⸗f</td>\n",
       "      <td>[Suffix Pron. sg.3.m.]</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>GIHCJ27JXVAM7GDUYWGEPKBRB4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>𓇋𓊪𓈖</td>\n",
       "      <td>jp〈t〉n</td>\n",
       "      <td>diese [Dem.Pron. pl.f.]</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>Z6HTGGPBPRDT3OZTZNXRF2GRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>𓁹𓊨𓀭</td>\n",
       "      <td>Wsr.w</td>\n",
       "      <td>Osiris (Totentitel des Verstorbenen)</td>\n",
       "      <td>epitheton_title</td>\n",
       "      <td>UCFJWBLRKJG4NJWTWT22WDR2MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>𓇓𓏏𓈖</td>\n",
       "      <td>nzw</td>\n",
       "      <td>König</td>\n",
       "      <td>substantive</td>\n",
       "      <td>LI5FJI4ZUJEMPIKS5RQ5HHNBUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>𓎟𓇿𓇿</td>\n",
       "      <td>nb-Tꜣ.DU</td>\n",
       "      <td>Herr der Beiden Länder (Könige)</td>\n",
       "      <td>epitheton_title</td>\n",
       "      <td>ICADWHGbHkfdokpooG4eCy3Zfe8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>𓎟𓁹𓐍𓏏𓏛</td>\n",
       "      <td>nb-jr(.t)-(j)ḫ.t</td>\n",
       "      <td>Herr des Rituals</td>\n",
       "      <td>epitheton_title</td>\n",
       "      <td>ICADWHT2O1dc30SXuRZUlquIDpM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>𓍹𓐼𓇋𓊃𓊪𓃭𓇿𓐽𓍺</td>\n",
       "      <td>Jsplt</td>\n",
       "      <td>Aspelta</td>\n",
       "      <td>entity_name</td>\n",
       "      <td>J3MLYALWVNAMDDG33VZ3RIEEUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>𓌷𓂝𓊤︂</td>\n",
       "      <td>mꜣꜥ-ḫrw</td>\n",
       "      <td>Gerechtfertigter (der selige Tote)</td>\n",
       "      <td>substantive</td>\n",
       "      <td>OKLGJLCEQFHU7HDRYUTYR352YA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unicode_hieroglyphs unicode_transcription  \\\n",
       "0                   𓂜𓈖                    nn   \n",
       "1                  𓎼𓎛𓀉                    gḥ   \n",
       "2               𓂝𓏏𓄹︀𓑀𓏥                ꜥ.t.PL   \n",
       "3                    𓆑                    ⸗f   \n",
       "4                  𓇋𓊪𓈖                jp〈t〉n   \n",
       "5                  𓁹𓊨𓀭                 Wsr.w   \n",
       "6                  𓇓𓏏𓈖                   nzw   \n",
       "7                  𓎟𓇿𓇿              nb-Tꜣ.DU   \n",
       "8                𓎟𓁹𓐍𓏏𓏛      nb-jr(.t)-(j)ḫ.t   \n",
       "9            𓍹𓐼𓇋𓊃𓊪𓃭𓇿𓐽𓍺                 Jsplt   \n",
       "10                𓌷𓂝𓊤︂               mꜣꜥ-ḫrw   \n",
       "\n",
       "                       lemma_translation   part-of-speech  \\\n",
       "0                    [Negationspartikel]         particle   \n",
       "1                              matt sein             verb   \n",
       "2                      Glied; Körperteil      substantive   \n",
       "3                 [Suffix Pron. sg.3.m.]          pronoun   \n",
       "4                diese [Dem.Pron. pl.f.]          pronoun   \n",
       "5   Osiris (Totentitel des Verstorbenen)  epitheton_title   \n",
       "6                                  König      substantive   \n",
       "7        Herr der Beiden Länder (Könige)  epitheton_title   \n",
       "8                       Herr des Rituals  epitheton_title   \n",
       "9                                Aspelta      entity_name   \n",
       "10    Gerechtfertigter (der selige Tote)      substantive   \n",
       "\n",
       "                        tokenID  \n",
       "0    22TFIMS2CBBCFFCDSCAIT3HR3Y  \n",
       "1    IOLUGQXLCRGNLMTAPJ65LI7MHU  \n",
       "2    GUVBJUGCSVF5VN55PN6RYS4YLI  \n",
       "3    GIHCJ27JXVAM7GDUYWGEPKBRB4  \n",
       "4    Z6HTGGPBPRDT3OZTZNXRF2GRDA  \n",
       "5    UCFJWBLRKJG4NJWTWT22WDR2MU  \n",
       "6    LI5FJI4ZUJEMPIKS5RQ5HHNBUE  \n",
       "7   ICADWHGbHkfdokpooG4eCy3Zfe8  \n",
       "8   ICADWHT2O1dc30SXuRZUlquIDpM  \n",
       "9    J3MLYALWVNAMDDG33VZ3RIEEUA  \n",
       "10   OKLGJLCEQFHU7HDRYUTYR352YA  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe and fill it\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_eg = pd.DataFrame({\n",
    "    'unicode_hieroglyphs': unicodeHiero,\n",
    "    'unicode_transcription': transcription,\n",
    "    'lemma_translation': translLemma,\n",
    "    'part-of-speech': posLemma,\n",
    "    'tokenID' : tokenID\n",
    "})\n",
    "\n",
    "df_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SFpyImV7u-x9"
   },
   "outputs": [],
   "source": [
    "# save as *.csv\n",
    "\n",
    "fileName = \"aspelta_TLA_Sentence_\" + sentenceID + \".csv\"\n",
    "df_eg.to_csv(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgqdyMX1Kq_8"
   },
   "source": [
    "## Akkadian Example 2:\n",
    "\n",
    "consider the following Akkadian text:\n",
    "\n",
    "http://www.achemenet.com//fr/item/?/sources-textuelles/textes-par-publication/Strassmaier_Cyrus/1665118\n",
    "\n",
    " 6 udu-nita<sub>2</sub> <i>ina</i> šu<sup>II</sup> <sup>Id</sup>en-gi a-<i>šú šá</i> <sup>Id</sup>[\n",
    "\n",
    " <i>a-na</i> 8 gín 4-<i>tú </i>kù-babbar<i> i-na</i> kù-babbar\n",
    "\n",
    " <i>šá</i> <i>i-di</i> é [ o o o ]<i> a-na</i> é-babbar-ra\n",
    "\n",
    " <i>it-ta-din</i> 5 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup><i>ka-ṣir</i>\n",
    "\n",
    " a-<i>šú šá</i> <sup>Id</sup>en-mu<i> a-na</i> 7 gín 4-<i>tú</i>\n",
    "\n",
    " kù-babbar <i>šá</i> <i>muh-hi</i> <i>dul-lu</i> <sup>I</sup>mu-mu\n",
    "\n",
    " <i>ú-šá-hi-su a-na</i> <i>lìb-bi</i> sì-<i>na</i>\n",
    "\n",
    " 1 udu-nita<sub>2</sub><i> a-na</i> 1 gín 4-<i>tú </i>kù-babbar\n",
    "\n",
    " <i>ina</i> šu<sup>II</sup> <sup>Id</sup>utu-ba-<i>šá</i><sup>!</sup> [\n",
    "\n",
    " 1 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup>DU-[\n",
    "\n",
    " <i>a-na</i> 1<sup>?</sup> gín [\n",
    "\n",
    " pap [13 udu-nita<sub>2</sub>-meš\n",
    "\n",
    " iti du<sub>6</sub> u<sub>4</sub> [o-kam] mu sag nam-lugal-la\n",
    "\n",
    " <sup>I</sup><i>ku-ra-áš</i> lugal tin-tir<sup>ki</sup> <i>u</i> kur-kur\n",
    "\n",
    "How would you preprocess this text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "e-5yKUGAHTOy"
   },
   "outputs": [],
   "source": [
    "akk2 = \"\"\" 6 udu-nita<sub>2</sub> <i>ina</i> šu<sup>II</sup> <sup>Id</sup>en-gi a-<i>šú šá</i> <sup>Id</sup>[\n",
    " <i>a-na</i> 8 gín 4-<i>tú</i> kù-babbar <i>i-na</i> kù-babbar\n",
    " <i>šá</i> <i>i-di</i> é [ o o o ] <i>a-na</i> é-babbar-ra\n",
    " <i>it-ta-din</i> 5 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup><i>ka-ṣir</i>\n",
    " a-<i>šú šá</i> <sup>Id</sup>en-mu <i>a-na</i> 7 gín 4-<i>tú</i>\n",
    " kù-babbar <i>šá</i> <i>muh-hi</i> <i>dul-lu</i> <sup>I</sup>mu-mu\n",
    " <i>ú-šá-hi-su a-na</i> <i>lìb-bi</i> sì-<i>na</i>\n",
    " 1 udu-nita<sub>2</sub> <i>a-na</i> 1 gín 4-<i>tú </i>kù-babbar\n",
    " <i>ina</i> šu<sup>II</sup> <sup>Id</sup>utu-ba-<i>šá</i><sup>!</sup> [\n",
    " 1 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup>DU-[\n",
    " <i>a-na</i> 1<sup>?</sup> gín [\n",
    " pap [13 udu-nita<sub>2</sub>-meš\n",
    " iti du<sub>6</sub> u<sub>4</sub> [o-kam] mu sag nam-lugal-la\n",
    " <sup>I</sup><i>ku-ra-áš</i> lugal tin-tir<sup>ki</sup> <i>u</i> kur-kur \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfxVT-PmNA9m",
    "outputId": "fac0f332-8fd9-4c58-97b9-a1f622ed4a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 6 udu-nita<sub>2</sub> <i>ina</i> šu<sup>II</sup> <sup>Id</sup>en-gi a-<i>šú šá</i> <sup>Id</sup>[', ' <i>a-na</i> 8 gín 4-<i>tú</i> kù-babbar <i>i-na</i> kù-babbar', ' <i>šá</i> <i>i-di</i> é [ o o o ] <i>a-na</i> é-babbar-ra', ' <i>it-ta-din</i> 5 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup><i>ka-ṣir</i>', ' a-<i>šú šá</i> <sup>Id</sup>en-mu <i>a-na</i> 7 gín 4-<i>tú</i>', ' kù-babbar <i>šá</i> <i>muh-hi</i> <i>dul-lu</i> <sup>I</sup>mu-mu', ' <i>ú-šá-hi-su a-na</i> <i>lìb-bi</i> sì-<i>na</i>', ' 1 udu-nita<sub>2</sub> <i>a-na</i> 1 gín 4-<i>tú </i>kù-babbar', ' <i>ina</i> šu<sup>II</sup> <sup>Id</sup>utu-ba-<i>šá</i><sup>!</sup> [', ' 1 udu-nita<sub>2</sub> <i>šá</i> <sup>I</sup>DU-[', ' <i>a-na</i> 1<sup>?</sup> gín [', ' pap [13 udu-nita<sub>2</sub>-meš', ' iti du<sub>6</sub> u<sub>4</sub> [o-kam] mu sag nam-lugal-la', ' <sup>I</sup><i>ku-ra-áš</i> lugal tin-tir<sup>ki</sup> <i>u</i> kur-kur ']\n"
     ]
    }
   ],
   "source": [
    "akk2_lines = akk2.split('\\n')\n",
    "print(akk2_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yd5Tm_Y6vg9R",
    "outputId": "39794692-93a3-4b5c-c998-26ec877b3bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line: 1\n",
      "1 ['6', {'sign_function': 'log'}]\n",
      "2 ['udu', {'sign_function': 'log'}]\n",
      "['nita<sub>2</sub>', {'sign_function': 'log'}]\n",
      "3 ['ina', {'sign_function': 'phon'}]\n",
      "4 ['šu', {'sign_function': 'log'}]\n",
      "['II', {'sign_function': 'class'}]\n",
      "['', {'sign_function': 'log'}]\n",
      "5 ['', {'sign_function': 'log'}]\n",
      "['Id', {'sign_function': 'class'}]\n",
      "['en', {'sign_function': 'log'}]\n",
      "['gi', {'sign_function': 'log'}]\n",
      "6 ['a', {'sign_function': 'log'}]\n",
      "['šú', {'sign_function': 'phon'}]\n",
      "7 ['šá', {'sign_function': 'phon'}]\n",
      "8 ['', {'sign_function': 'log'}]\n",
      "['Id', {'sign_function': 'class'}]\n",
      "['[', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 2\n",
      "1 ['a', {'sign_function': 'phon'}]\n",
      "['na', {'sign_function': 'phon'}]\n",
      "2 ['8', {'sign_function': 'log'}]\n",
      "3 ['gín', {'sign_function': 'log'}]\n",
      "4 ['4', {'sign_function': 'log'}]\n",
      "['tú</i>', {'sign_function': 'phon'}]\n",
      "5 ['kù', {'sign_function': 'log'}]\n",
      "['babbar', {'sign_function': 'log'}]\n",
      "6 ['i', {'sign_function': 'phon'}]\n",
      "['na', {'sign_function': 'phon'}]\n",
      "7 ['kù', {'sign_function': 'log'}]\n",
      "['babbar', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 3\n",
      "1 ['šá', {'sign_function': 'phon'}]\n",
      "2 ['i', {'sign_function': 'phon'}]\n",
      "['di', {'sign_function': 'phon'}]\n",
      "3 ['é', {'sign_function': 'log'}]\n",
      "4 ['[', {'sign_function': 'log'}]\n",
      "5 ['o', {'sign_function': 'log'}]\n",
      "6 ['o', {'sign_function': 'log'}]\n",
      "7 ['o', {'sign_function': 'log'}]\n",
      "8 [']', {'sign_function': 'log'}]\n",
      "9 ['a', {'sign_function': 'phon'}]\n",
      "['na', {'sign_function': 'phon'}]\n",
      "10 ['é', {'sign_function': 'log'}]\n",
      "['babbar', {'sign_function': 'log'}]\n",
      "['ra', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 4\n",
      "1 ['it', {'sign_function': 'phon'}]\n",
      "['ta', {'sign_function': 'phon'}]\n",
      "['din', {'sign_function': 'phon'}]\n",
      "2 ['5', {'sign_function': 'log'}]\n",
      "3 ['udu', {'sign_function': 'log'}]\n",
      "['nita<sub>2</sub>', {'sign_function': 'log'}]\n",
      "4 ['šá', {'sign_function': 'phon'}]\n",
      "5 ['<sup>I</sup><i>ka-ṣir', {'sign_function': 'phon'}]\n",
      "------------------\n",
      "line: 5\n",
      "1 ['a', {'sign_function': 'log'}]\n",
      "['šú', {'sign_function': 'phon'}]\n",
      "2 ['šá', {'sign_function': 'phon'}]\n",
      "3 ['', {'sign_function': 'log'}]\n",
      "['Id', {'sign_function': 'class'}]\n",
      "['en', {'sign_function': 'log'}]\n",
      "['mu', {'sign_function': 'log'}]\n",
      "4 ['a', {'sign_function': 'phon'}]\n",
      "['na', {'sign_function': 'phon'}]\n",
      "5 ['7', {'sign_function': 'log'}]\n",
      "6 ['gín', {'sign_function': 'log'}]\n",
      "7 ['4', {'sign_function': 'log'}]\n",
      "['tú</i>', {'sign_function': 'phon'}]\n",
      "------------------\n",
      "line: 6\n",
      "1 ['kù', {'sign_function': 'log'}]\n",
      "['babbar', {'sign_function': 'log'}]\n",
      "2 ['šá', {'sign_function': 'phon'}]\n",
      "3 ['muh', {'sign_function': 'phon'}]\n",
      "['hi', {'sign_function': 'phon'}]\n",
      "4 ['dul', {'sign_function': 'phon'}]\n",
      "['lu', {'sign_function': 'phon'}]\n",
      "5 ['', {'sign_function': 'log'}]\n",
      "['I', {'sign_function': 'class'}]\n",
      "['mu', {'sign_function': 'log'}]\n",
      "['mu', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 7\n",
      "1 ['<i>ú', {'sign_function': 'log'}]\n",
      "['šá', {'sign_function': 'log'}]\n",
      "['hi', {'sign_function': 'log'}]\n",
      "['su', {'sign_function': 'log'}]\n",
      "2 ['a-na', {'sign_function': 'phon'}]\n",
      "3 ['lìb', {'sign_function': 'phon'}]\n",
      "['bi', {'sign_function': 'phon'}]\n",
      "4 ['sì', {'sign_function': 'log'}]\n",
      "['na</i>', {'sign_function': 'phon'}]\n",
      "------------------\n",
      "line: 8\n",
      "1 ['1', {'sign_function': 'log'}]\n",
      "2 ['udu', {'sign_function': 'log'}]\n",
      "['nita<sub>2</sub>', {'sign_function': 'log'}]\n",
      "3 ['a', {'sign_function': 'phon'}]\n",
      "['na', {'sign_function': 'phon'}]\n",
      "4 ['1', {'sign_function': 'log'}]\n",
      "5 ['gín', {'sign_function': 'log'}]\n",
      "6 ['4', {'sign_function': 'log'}]\n",
      "['tú', {'sign_function': 'phon'}]\n",
      "7 ['</i>kù', {'sign_function': 'log'}]\n",
      "['babbar', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 9\n",
      "1 ['ina', {'sign_function': 'phon'}]\n",
      "2 ['šu', {'sign_function': 'log'}]\n",
      "['II', {'sign_function': 'class'}]\n",
      "['', {'sign_function': 'log'}]\n",
      "3 ['<sup>Id</sup>utu', {'sign_function': 'log'}]\n",
      "['ba', {'sign_function': 'log'}]\n",
      "['šá</i><sup>!</sup>', {'sign_function': 'phon'}]\n",
      "4 ['[', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 10\n",
      "1 ['1', {'sign_function': 'log'}]\n",
      "2 ['udu', {'sign_function': 'log'}]\n",
      "['nita<sub>2</sub>', {'sign_function': 'log'}]\n",
      "3 ['šá', {'sign_function': 'phon'}]\n",
      "4 ['', {'sign_function': 'log'}]\n",
      "['I', {'sign_function': 'class'}]\n",
      "['DU', {'sign_function': 'log'}]\n",
      "['[', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 11\n",
      "1 ['a', {'sign_function': 'phon'}]\n",
      "['na', {'sign_function': 'phon'}]\n",
      "2 ['1', {'sign_function': 'log'}]\n",
      "['?', {'sign_function': 'class'}]\n",
      "['', {'sign_function': 'log'}]\n",
      "3 ['gín', {'sign_function': 'log'}]\n",
      "4 ['[', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 12\n",
      "1 ['pap', {'sign_function': 'log'}]\n",
      "2 ['[13', {'sign_function': 'log'}]\n",
      "3 ['udu', {'sign_function': 'log'}]\n",
      "['nita<sub>2</sub>', {'sign_function': 'log'}]\n",
      "['meš', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 13\n",
      "1 ['iti', {'sign_function': 'log'}]\n",
      "2 ['du<sub>6</sub>', {'sign_function': 'log'}]\n",
      "3 ['u<sub>4</sub>', {'sign_function': 'log'}]\n",
      "4 ['[o', {'sign_function': 'log'}]\n",
      "['kam]', {'sign_function': 'log'}]\n",
      "5 ['mu', {'sign_function': 'log'}]\n",
      "6 ['sag', {'sign_function': 'log'}]\n",
      "7 ['nam', {'sign_function': 'log'}]\n",
      "['lugal', {'sign_function': 'log'}]\n",
      "['la', {'sign_function': 'log'}]\n",
      "------------------\n",
      "line: 14\n",
      "1 ['<sup>I</sup><i>ku-ra-áš', {'sign_function': 'phon'}]\n",
      "2 ['lugal', {'sign_function': 'log'}]\n",
      "3 ['tin', {'sign_function': 'log'}]\n",
      "['tir', {'sign_function': 'log'}]\n",
      "['ki', {'sign_function': 'class'}]\n",
      "['', {'sign_function': 'log'}]\n",
      "4 ['u', {'sign_function': 'phon'}]\n",
      "5 ['kur', {'sign_function': 'log'}]\n",
      "['kur', {'sign_function': 'log'}]\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "line_count = 1\n",
    "for line in akk2_lines:\n",
    "    print(\"line:\", line_count)\n",
    "    words = line.split()\n",
    "    word_count = 1\n",
    "\n",
    "    for word in words :\n",
    "        print(word_count, end=\" \")\n",
    "\n",
    "        if word.startswith(\"<i>\") and word.endswith(\"</i>\") :\n",
    "            #print(word)\n",
    "            signList = word.split(\"-\")\n",
    "            for sign in signList :\n",
    "            #print(sign)\n",
    "                sign = sign.replace(\"<i>\", \"\")\n",
    "                sign = sign.replace(\"</i>\", \"\")\n",
    "                sign = [sign, {\"sign_function\": \"phon\" }]\n",
    "                print(sign)\n",
    "        elif \"-<i>\" in word :\n",
    "            signList = word.split(\"-\")\n",
    "            for sign in signList :\n",
    "            #print(sign)\n",
    "                if sign.startswith(\"<i>\") :\n",
    "                    sign = sign.replace(\"<i>\", \"\")\n",
    "                    sign = [sign, {\"sign_function\": \"phon\" }]\n",
    "                    print(sign)\n",
    "                else:\n",
    "                    print([sign, {\"sign_function\": \"log\" }])\n",
    "\n",
    "        elif word.endswith(\"</i>\") :\n",
    "            word = word.replace(\"</i>\", \"\")\n",
    "            word = [word, {\"sign_function\": \"phon\" }]\n",
    "            print(word)\n",
    "        #elif :\n",
    "           # print(word)\n",
    "        elif \"</sup\" in word :\n",
    "            #print(word.split(\"-\"), \"logogram\")\n",
    "            signCluster = word.split(\"-\")\n",
    "            #print(signCluster)\n",
    "            for elem in signCluster :\n",
    "                if \"</sup>\" in elem :\n",
    "                    #print(\"yes\")\n",
    "                    elem = elem.replace(\"</sup>\", \"</class>-\")\n",
    "                    elem = elem.replace(\"<sup>\", \"-<class>\")\n",
    "                    signs = elem.split(\"-\")\n",
    "                    for sign in signs :\n",
    "                        if sign.startswith(\"<class>\") and sign.endswith(\"</class>\"):\n",
    "                            print([sign[7:-8], {\"sign_function\": \"class\" }])\n",
    "\n",
    "                        else:\n",
    "                            print([sign, {\"sign_function\": \"log\" }])\n",
    "                else:\n",
    "                    print([elem, {\"sign_function\": \"log\" }])\n",
    "        else:\n",
    "          if \"-\" in word :\n",
    "            signs = word.split(\"-\")\n",
    "            for sign in signs :\n",
    "              print([sign, {\"sign_function\": \"log\" }])\n",
    "          else:\n",
    "            print([word, {\"sign_function\": \"log\" }])\n",
    "\n",
    "        word_count +=1\n",
    "\n",
    "    line_count += 1\n",
    "    print(\"------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAMz_a66jCSm"
   },
   "source": [
    "*This notebook was created by [Eliese-Sophia Lincke](https://www.berliner-antike-kolleg.org/en/bak/team/fda/eliese-sophia_lincke/index.html) and [Shai Gordin](https://digitalpasts.github.io/) in Fall 2024 for the course [Ancient Language Processing](https://digitalpasts.github.io/ALP-course/), incorporating materials from [Avital Romach](https://github.com/ARomach).*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
>>>>>>> 8c6168e (add some own solutions to brush up my python)
